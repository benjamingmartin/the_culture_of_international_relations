{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Culture of International Relations - Text Analysis\n",
    "### <span style='color: green'>SETUP </span> Prepare and Setup Notebook <span style='float: right; color: red'>MANDATORY</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Setup\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys, os, collections, zipfile\n",
    "import re, typing.re\n",
    "\n",
    "sys.path = list(set(['.', '..']) - set(sys.path)) + sys.path\n",
    "\n",
    "import nltk, textacy, spacy \n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "import bokeh, bokeh.plotting, bokeh.models, matplotlib.pyplot as plt\n",
    "import common.utility as utility\n",
    "import common.widgets_utility as widgets_utility\n",
    "import common.widgets_config as widgets_config\n",
    "import common.config as config\n",
    "import common.utility as utility\n",
    "import common.treaty_utility as treaty_utility\n",
    "import common.treaty_state as treaty_repository\n",
    "import treaty_corpus\n",
    "import types, glob\n",
    "\n",
    "from beakerx.object import beakerx\n",
    "from beakerx import *\n",
    "from IPython.display import display, set_matplotlib_formats\n",
    "\n",
    "logger = utility.getLogger('corpus_text_analysis')\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "pd.options.display.colheader_justify = 'left'\n",
    "\n",
    "DATA_FOLDER = '../data'\n",
    "PATTERN = '*.txt'\n",
    "PERIOD_GROUP = 'years_1945-1972'\n",
    "DF_TAGSET = pd.read_csv('../data/tagset.csv', sep='\\t').fillna('')\n",
    "WTI_INDEX = treaty_repository.load_wti_index(data_folder=DATA_FOLDER) # FIXME: Use: treaty_repository.load_wti_index_with_gui(data_folder=DATA_FOLDER)\n",
    "GPE_FILENAME = os.path.join(DATA_FOLDER, 'gpe_substitutions.txt')\n",
    "\n",
    "%matplotlib inline\n",
    "bokeh.plotting.output_notebook()\n",
    "\n",
    "current_corpus_container = lambda: textacy_utility.CorpusContainer.container()\n",
    "current_corpus = lambda: textacy_utility.CorpusContainer.corpus()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color: green'>PREPARE </span> Load and Prepare Corpus <span style='float: right; color: red'>MANDATORY</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textacy_corpus_gui\n",
    "try:\n",
    "    textacy_corpus_gui.display_corpus_load_gui(DATA_FOLDER, WTI_INDEX, current_corpus_container())\n",
    "except Exception as ex:\n",
    "    logger.error(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color: green'>EXPLORE </span> Document Similarity <span style='float: right; color: red'>WORK IN PROGRESS</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "def sumorial(n):\n",
    "    return int(n * (n + 1) / 2)\n",
    "\n",
    "def compute_similarity(corpus, metric, extract_token_args, tick=utility.noop):\n",
    "    document_tokens = [ list(x) for x in textacy_utility.extract_corpus_terms(corpus, extract_token_args) ]\n",
    "    n = sumorial(len(document_tokens))\n",
    "    tick(0)\n",
    "    row = np.zeros(n, dtype=int)\n",
    "    col = np.zeros(n, dtype=int)\n",
    "    data = np.zeros(n, dtype=int)\n",
    "    p = 0\n",
    "    for i in range(1, n-1):\n",
    "        tick()\n",
    "        for j in range(i+1, len(document_tokens)):\n",
    "            data[p] = metric.score(document_tokens[i], document_tokens[j])\n",
    "            row[p] = i\n",
    "            col[p] = j\n",
    "            p += 1\n",
    "    m = scipy.sparse.coo_matrix((data, (row, col)), shape=(n,n))\n",
    "    tick(0)\n",
    "    return m\n",
    "\n",
    "gui = types.SimpleNamespace(\n",
    "    progress=widgets.IntProgress(min=0, max=len(document_tokens), value=0)\n",
    ")\n",
    "\n",
    "display(gui.progress)\n",
    "\n",
    "extract_token_args = dict(\n",
    "    args=dict(\n",
    "        ngrams=[ 1 ],\n",
    "        named_entities=False,\n",
    "        normalize='lemma',\n",
    "        as_strings=True\n",
    "    ),\n",
    "    kwargs=dict(\n",
    "        min_freq=2,\n",
    "        include_pos=['NOUN', 'PROPN'],\n",
    "        filter_stops=True,\n",
    "        filter_punct=True\n",
    "    ),\n",
    "    mask_gpe=True,\n",
    "    min_freq=2, # tokens below this threshold is added to extra_stop_words\n",
    "    max_doc_freq=100,\n",
    "    extra_stop_words=set([]),\n",
    "    min_length=2\n",
    ")\n",
    "\n",
    "def tick(n=None):\n",
    "    gui.progress.value = n if n is not None else gui.progress.value + 1\n",
    "\n",
    "corpus = get_current_corpus().textacy_corpus\n",
    "metric = Hirschberg()\n",
    "gui.progress.max = len(document_tokens)\n",
    "\n",
    "m = compute_similarity(corpus, metric, extract_token_args, tick=tick)\n",
    "\n",
    "treaty_index = { doc.metadata['treaty_id']: i for i, doc in enumerate(corpus) }\n",
    "\n",
    "#df.to_excel('hirschberg_scores_lemma_noun.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({ 'treaty_i': list(m.row), 'treaty_j': list(m.col), 'score': list(m.data) })\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_i = df.set_index('treaty_i').merge(WTI_INDEX.treaties[['signed_year', 'party1', 'party2']], how='inner', left_index=True, right_index=True).reset_index().rename(columns={ 'index': 'treaty_i', 'signed_year': 'signed_year_i', 'party1': 'party1_i', 'party2': 'party2_i'})\n",
    "df_ij = df_i.set_index('treaty_j').merge(WTI_INDEX.treaties[['signed_year', 'party1', 'party2']], how='inner', left_index=True, right_index=True).reset_index().rename(columns={ 'index': 'treaty_j', 'signed_year': 'signed_year_j', 'party1': 'party1_j', 'party2': 'party2_j'})\n",
    "\n",
    "document_tokens = [ list(x) for x in textacy_utility.extract_corpus_terms(corpus, extract_token_args) ]\n",
    "\n",
    "#treaty_index\n",
    "output_left = widgets.Output()\n",
    "output_right = widgets.Output()\n",
    "\n",
    "display(widgets.HBox([output_left, output_right]))\n",
    "df_ij.sort_values('score', ascending=False).head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Textacy Similarity\n",
    "\n",
    "```\n",
    "textacy.similarity.word_movers(doc1, doc2, metric='cosine')\n",
    "Measure the semantic similarity between two documents using Word Movers Distance.\n",
    "\n",
    "Parameters:\t\n",
    "doc1 (textacy.Doc or spacy.Doc) –\n",
    "doc2 (textacy.Doc or spacy.Doc) –\n",
    "metric ({'cosine', 'euclidean', 'l1', 'l2', 'manhattan'}) –\n",
    "Returns:\t\n",
    "Similarity between doc1 and doc2 in the interval [0.0, 1.0], where larger values correspond to more similar documents.\n",
    "\n",
    "Return type:\t\n",
    "float\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textacy.similarity\n",
    "\n",
    "corpus = current_corpus()\n",
    "\n",
    "doc1 = corpus[0]\n",
    "doc2 = corpus[3]\n",
    "\n",
    "metric_options = [ ('Cosine', 'cosine'), ('Euclidean', 'euclidean'), ('L1', 'l1'), ('L2', 'l2'), ('Manhattan', 'manhattan') ] \n",
    "\n",
    "gui = types.SimpleNamespace(\n",
    "    metric=widgets.Dropdown(description='Metric', options=metric_options, value=metric_options[0][1]),\n",
    "    index=widgets.IntSlider(description='Document', min=0,max=len(corpus)-1, step=1, value=0)\n",
    ")\n",
    "\n",
    "display(gui.metric)\n",
    "display(gui.index)\n",
    "\n",
    "score = textacy.similarity.word_movers(doc1, doc2, metric='cosine')\n",
    "\n",
    "score\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 655.4,
   "position": {
    "height": "886px",
    "left": "1049px",
    "right": "20px",
    "top": "110px",
    "width": "654px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}