{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Culture of International Relations - Text Analysis\n",
    "### <span style='color: green'>SETUP </span> Prepare and Setup Notebook <span style='float: right; color: red'>MANDATORY</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-27 14:40:08,150 : INFO : Reading file: Treaties_Master_List_Treaties.csv...\n",
      "2019-09-27 14:40:08,605 : INFO : Reading file: country_continent.csv...\n",
      "2019-09-27 14:40:08,612 : INFO : Reading file: parties_curated_parties.csv...\n",
      "2019-09-27 14:40:08,622 : INFO : Reading file: parties_curated_continent.csv...\n",
      "2019-09-27 14:40:08,628 : INFO : Reading file: parties_curated_group.csv...\n",
      "2019-09-27 14:40:08,694 : INFO : WTI index loaded!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f95baf231ee4ba6969ed5272f3caba8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(IntProgress(value=0, layout=Layout(width='90%'), max=5), HBox(children=(Dropdown(description='C…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Setup\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import ipywidgets as widgets\n",
    "\n",
    "sys.path = list(set(['..', '../3_text_analysis']) - set(sys.path)) + sys.path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import common.utility as utility\n",
    "import common.treaty_utility as treaty_utility\n",
    "import common.treaty_state as treaty_repository\n",
    "import treaty_corpus\n",
    "import textacy_corpus_utility as textacy_utility\n",
    "from beakerx.object import beakerx\n",
    "from beakerx import *\n",
    "from IPython.display import display, set_matplotlib_formats\n",
    "\n",
    "logger = utility.getLogger('corpus_text_analysis')\n",
    "\n",
    "DATA_FOLDER = '../data'\n",
    "WTI_INDEX = treaty_repository.load_wti_index(data_folder=DATA_FOLDER)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "current_corpus_container = lambda: textacy_utility.CorpusContainer.container()\n",
    "current_corpus = lambda: textacy_utility.CorpusContainer.corpus()\n",
    "\n",
    "import textacy_corpus_gui\n",
    "\n",
    "try:\n",
    "    container = current_corpus_container()\n",
    "    textacy_corpus_gui.display_corpus_load_gui(DATA_FOLDER, WTI_INDEX, container)\n",
    "except Exception as ex:\n",
    "    logger.error(ex)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute word in document per year frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "789a61da228142c18ffc628043ed92f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Normalize', index=2, layout=Layout(width='200px'), options…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "def compute_doc_frequencies(corpus, token_to_find, normalize='lemma'):\n",
    "    f =  { 'lemma': lambda x: x.lemma_, 'lower': lambda x: x.lower_, 'orth': lambda x: x.orth_ }[normalize]\n",
    "    token_to_find = token_to_find.lower() if normalize != 'orth' else token_to_find\n",
    "    data = {}\n",
    "    for doc in corpus:\n",
    "        signed_year = doc._.meta['signed_year']\n",
    "        if signed_year not in data:\n",
    "            data[signed_year] = { 'signed_year': signed_year,  'match_count': 0, 'total_count': 0}\n",
    "        data[signed_year]['total_count'] += 1\n",
    "        if token_to_find in [ f(x) for x in doc ]:\n",
    "            data[signed_year]['match_count'] += 1\n",
    "    df = pd.DataFrame(list(data.values())).set_index('signed_year')\n",
    "    df['doc_frequency'] = (df.match_count / df.total_count) * 100\n",
    "    df = df[['total_count', 'match_count', 'doc_frequency']]\n",
    "    return df\n",
    "\n",
    "def word_doc_frequencies_gui(corpus):\n",
    "    normalize_options   = { 'Text':  'orth', 'Lemma': 'lemma', 'Lower': 'lower' }\n",
    "    \n",
    "    gui = types.SimpleNamespace(\n",
    "        normalize=widgets.Dropdown(description='Normalize', options=normalize_options, value='lemma', layout=widgets.Layout(width='200px')),\n",
    "        compute=widgets.Button(description='Compute', button_style='Success', layout=widgets.Layout(width='120px')),\n",
    "        token=widgets.Text(description='Word'),\n",
    "        output=widgets.Output(layout={'border': '1px solid black'})\n",
    "    )\n",
    "    \n",
    "    boxes = widgets.VBox([\n",
    "        widgets.HBox([\n",
    "            gui.normalize,\n",
    "            gui.token,\n",
    "            gui.compute\n",
    "        ]),\n",
    "        gui.output\n",
    "    ])\n",
    "    \n",
    "    display(boxes)\n",
    "    \n",
    "    def compute_callback_handler(*_args):\n",
    "        gui.output.clear_output()\n",
    "        with gui.output:\n",
    "            try:\n",
    "                gui.compute.disabled = True\n",
    "                df_counts = compute_doc_frequencies(\n",
    "                    corpus=corpus,\n",
    "                    token_to_find=gui.token.value,\n",
    "                    normalize=gui.normalize.value\n",
    "                )\n",
    "                display(df_counts)\n",
    "            except Exception as ex:\n",
    "                logger.error(ex)\n",
    "                raise\n",
    "            finally:\n",
    "                gui.compute.disabled = False\n",
    "\n",
    "    gui.compute.on_click(compute_callback_handler)\n",
    "\n",
    "try:\n",
    "    word_doc_frequencies_gui(current_corpus())\n",
    "except Exception as ex:\n",
    "    logger.error(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 655.4,
   "position": {
    "height": "886px",
    "left": "1049px",
    "right": "20px",
    "top": "110px",
    "width": "654px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
