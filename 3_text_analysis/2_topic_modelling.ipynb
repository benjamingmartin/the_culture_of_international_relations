{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Culture of International Relations - Text Analysis\n",
    "### <span style='color: green'>SETUP </span> Prepare and Setup Notebook <span style='float: right; color: red'>MANDATORY</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-04 15:49:59,804 : INFO : WTI index loaded!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1002\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1002\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1002\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '1002' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.3.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.3.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.3.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.0.3.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-1.0.3.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.3.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.3.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.3.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.3.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.3.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1002\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };var element = document.getElementById(\"1002\");\n  if (element == null) {\n    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '1002' but no matching script tag was found. \")\n    return false;\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.3.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.3.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.3.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.0.3.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-1.0.3.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.3.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.3.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.3.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.3.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.3.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Setup\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys, os, collections, zipfile\n",
    "import re, typing.re\n",
    "\n",
    "sys.path = list(set(['.', '..']) - set(sys.path)) + sys.path\n",
    "\n",
    "import nltk, textacy, spacy \n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "import bokeh, bokeh.plotting, bokeh.models, matplotlib.pyplot as plt\n",
    "import common.utility as utility\n",
    "import common.widgets_utility as widgets_utility\n",
    "import common.widgets_config as widgets_config\n",
    "import common.config as config\n",
    "import common.utility as utility\n",
    "import common.treaty_utility as treaty_utility\n",
    "import common.treaty_state as treaty_repository\n",
    "import treaty_corpus\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning) \n",
    "\n",
    "from beakerx.object import beakerx\n",
    "from beakerx import *\n",
    "from IPython.display import display, set_matplotlib_formats\n",
    "\n",
    "logger = utility.getLogger('corpus_text_analysis')\n",
    "\n",
    "import pickle\n",
    "import topic_model\n",
    "import topic_model_utility\n",
    "import textacy_corpus_utility as textacy_utility\n",
    "\n",
    "utility.setup_default_pd_display(pd)\n",
    "\n",
    "DATA_FOLDER, PATTERN = '../data',  '*.txt'\n",
    "PERIOD_GROUP = 'years_1945-1972'\n",
    "DF_TAGSET = pd.read_csv('../data/tagset.csv', sep='\\t').fillna('')\n",
    "WTI_INDEX = treaty_repository.load_wti_index(data_folder=DATA_FOLDER)\n",
    "TREATY_TIME_GROUPINGS = WTI_INDEX.get_treaty_time_groupings()\n",
    "\n",
    "%matplotlib inline\n",
    "# set_matplotlib_formats('svg')   \n",
    "bokeh.plotting.output_notebook()\n",
    "\n",
    "current_corpus_container = lambda: textacy_utility.CorpusContainer.container()\n",
    "current_corpus = lambda: textacy_utility.CorpusContainer.corpus()\n",
    "\n",
    "current_state = lambda: topic_model_utility.TopicModelContainer.singleton()\n",
    "current_data = lambda: current_state().data\n",
    "current_topic_model = lambda: current_state().topic_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color: green'>PREPARE </span> Load and Prepare Corpus <span style='float: right; color: red'>MANDATORY</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eafa56cd23094ee88df0416bab32d7e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(IntProgress(value=0, layout=Layout(width='90%'), max=5), HBox(children=(Dropdown(description='C…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import textacy_corpus_gui\n",
    "try:\n",
    "    textacy_corpus_gui.display_corpus_load_gui(DATA_FOLDER, WTI_INDEX, current_corpus_container())\n",
    "except Exception as ex:\n",
    "    logger.error(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color: green;'>MODEL</span> Compute or Load a Topic Model<span style='color: red; float: right'>MANDATORY RUN</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color: green;'>MODEL</span> Compute a new Topic Model<span style='color: red; float: right'>OPTIONAL</span>\n",
    "\n",
    "<span style='color: red'>TODO</span>: Check if display order is correct (compare to relevant_topic_ids order)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d92ccd85ab4441f8316475c4d8840d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(IntProgress(value=0, layout=Layout(width='90%'), max=5), HBox(children=(VBox(children=(IntSlide…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import topic_model_gui\n",
    "try:\n",
    "    topic_model_gui.display_topic_model_gui(current_state(), current_corpus(), DF_TAGSET)\n",
    "except Exception as ex:\n",
    "    raise\n",
    "    logger.error(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color: green;'>MODEL</span> Store or Load a Topic Model<span style='color: red; float: right'>OPTIONAL</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78446f701c3948a3b5fa0f2c3f0c0da3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Path', layout=Layout(width='40%'), options=('../data/topic…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "import glob\n",
    "import topic_model\n",
    "import topic_model_utility\n",
    "\n",
    "def get_persisted_model_paths():\n",
    "    return sorted([ x for x in glob.glob(os.path.join(DATA_FOLDER, '*.pickle')) ])\n",
    "\n",
    "def get_store_filename(identifier):\n",
    "    filename = os.path.join(DATA_FOLDER, 'topic_model.pickle')\n",
    "    filename = utility.path_add_date(filename)\n",
    "    filename = utility.path_add_suffix(filename, identifier)\n",
    "    return filename\n",
    "    \n",
    "def display_persist_topic_model_gui(state):\n",
    "    \n",
    "    gui = types.SimpleNamespace(\n",
    "        stored_path=widgets.Dropdown(description='Path', options=get_persisted_model_paths(), layout=widgets.Layout(width='40%')),\n",
    "        load=widgets.Button(description='Load', button_style='Success', layout=widgets.Layout(width='80px')),\n",
    "        store=widgets.Button(description='Store', button_style='Success', layout=widgets.Layout(width='80px')),\n",
    "        identifier=widgets.Text(description='Identifier', layout=widgets.Layout(width='300px')),\n",
    "        output=widgets.Output()\n",
    "    )\n",
    "    \n",
    "    boxes = widgets.VBox([\n",
    "        widgets.HBox([gui.stored_path, gui.load, gui.store, gui.identifier ]),\n",
    "        widgets.HBox([\n",
    "            widgets.Label(value=\"\", layout=widgets.Layout(width='40%')),\n",
    "            widgets.Label(value=\"Stored models will be named ./data/topic_model_yyyymmdd_$identifier$.pickle\", layout=widgets.Layout(width='40%')),\n",
    "        ]),\n",
    "        widgets.VBox([gui.output])\n",
    "    ])\n",
    "    \n",
    "    def load_handler(*args):\n",
    "        \n",
    "        with gui.output:\n",
    "            \n",
    "            if gui.stored_path.value is None:\n",
    "                print(\"Please specify which model to load.\")\n",
    "                return\n",
    "\n",
    "            state.data = topic_model.load_model(gui.stored_path.value)\n",
    "\n",
    "            topics = topic_model_utility.get_lda_topics(state.topic_model, n_tokens=20)\n",
    "\n",
    "            display(topics)\n",
    "\n",
    "    def store_handler(*args):\n",
    "        \n",
    "        gui.output.clear_output()\n",
    "\n",
    "        with gui.output:\n",
    "\n",
    "            if gui.identifier.value == '':\n",
    "                print(\"Please specify a unique identifier for the model.\")\n",
    "                return\n",
    "\n",
    "            if gui.identifier.value != utility.filename_whitelist(gui.identifier.value):\n",
    "                print(\"Please use ONLY valid filename characters in identifier.\")\n",
    "                return\n",
    "\n",
    "            filename = get_store_filename(gui.identifier.value)\n",
    "\n",
    "            topic_model.store_model(state.data, filename)\n",
    "\n",
    "            gui.stored_path.options = get_persisted_model_paths()\n",
    "            gui.stored_path.value = filename if filename in gui.stored_path.options else None\n",
    "\n",
    "            print('Model stored in file {}'.format(filename))\n",
    "            \n",
    "    gui.load.on_click(load_handler)\n",
    "    gui.store.on_click(store_handler)\n",
    "    \n",
    "    display(boxes)\n",
    "\n",
    "display_persist_topic_model_gui(current_state())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color: green;'>VISUALIZE</span> Display Topic's Word Distribution as a Wordcloud<span style='color: red; float: right'>TRY IT</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8e1f20cf7124a7494f63b1f773e0849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=\"<span class='tx02'></span>\", placeholder=''), HBox(children=(Button(description='<<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display LDA topic's token wordcloud\n",
    "opts = { 'max_font_size': 100, 'background_color': 'white', 'width': 900, 'height': 600 }\n",
    "import wordcloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_wordcloud(df, token='token', weight='weight', figsize=(14, 14/1.618), **args):\n",
    "    token_weights = dict({ tuple(x) for x in df[[token, weight]].values })\n",
    "    image = wordcloud.WordCloud(**args,)\n",
    "    image.fit_words(token_weights)\n",
    "    plt.figure(figsize=figsize) #, dpi=100)\n",
    "    plt.imshow(image, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "def display_wordcloud(\n",
    "    state,\n",
    "    topic_id=0,\n",
    "    n_words=100,\n",
    "    output_format='Wordcloud',\n",
    "    gui=None\n",
    "):\n",
    "    def tick(n=None):\n",
    "        gui.progress.value = (gui.progress.value + 1) if n is None else n\n",
    "        \n",
    "    if gui.n_topics != state.num_topics:\n",
    "        gui.n_topics = state.num_topics\n",
    "        gui.topic_id.value = 0\n",
    "        gui.topic_id.max=state.num_topics - 1\n",
    "        \n",
    "    tick(1)\n",
    "    \n",
    "    topic_token_weights = state.processed.topic_token_weights\n",
    "    \n",
    "    df = topic_token_weights.loc[(topic_token_weights.topic_id == topic_id)]\n",
    "    \n",
    "    tokens = topic_model_utility.get_topic_title(topic_token_weights, topic_id, n_tokens=n_words)\n",
    "    gui.text.value = 'ID {}: {}'.format(topic_id, tokens)\n",
    "   \n",
    "    tick()\n",
    "    \n",
    "    if output_format == 'Wordcloud':\n",
    "        plot_wordcloud(df, 'token', 'weight', max_words=n_words, **opts)\n",
    "    else:\n",
    "        tick()\n",
    "        df = topic_model_utility.get_topic_tokens(topic_token_weights, topic_id=topic_id, n_words=n_words)\n",
    "        tick()\n",
    "        display(df)\n",
    "    tick(0)\n",
    "    \n",
    "def display_wordcloud_gui(state):\n",
    "    \n",
    "    output_options = ['Wordcloud', 'Table']\n",
    "    text_id = 'tx02'\n",
    "    \n",
    "    gui = widgets_utility.WidgetUtility(\n",
    "        n_topics=state.num_topics,\n",
    "        text_id=text_id,\n",
    "        text=widgets_config.text(text_id),\n",
    "        topic_id=widgets.IntSlider(description='Topic ID', min=0, max=state.num_topics - 1, step=1, value=0, continuous_update=False),\n",
    "        word_count=widgets.IntSlider(description='#Words', min=5, max=250, step=1, value=25, continuous_update=False),\n",
    "        output_format=widgets.Dropdown(description='Format', options=output_options, value=output_options[0], layout=widgets.Layout(width=\"200px\")),\n",
    "        progress=widgets.IntProgress(min=0, max=4, step=1, value=0, layout=widgets.Layout(width=\"95%\"))\n",
    "    )\n",
    "\n",
    "    gui.prev_topic_id = gui.create_prev_id_button('topic_id', state.num_topics)\n",
    "    gui.next_topic_id = gui.create_next_id_button('topic_id', state.num_topics)\n",
    "\n",
    "    iw = widgets.interactive(\n",
    "        display_wordcloud,\n",
    "        state=widgets.fixed(state),\n",
    "        topic_id=gui.topic_id,\n",
    "        n_words=gui.word_count,\n",
    "        output_format=gui.output_format,\n",
    "        gui=widgets.fixed(gui)\n",
    "    )\n",
    "\n",
    "    display(widgets.VBox([\n",
    "        gui.text,\n",
    "        widgets.HBox([gui.prev_topic_id, gui.next_topic_id, gui.topic_id, gui.word_count, gui.output_format]),\n",
    "        gui.progress,\n",
    "        iw.children[-1]\n",
    "    ]))\n",
    "\n",
    "    iw.update()\n",
    "\n",
    "try:\n",
    "    display_wordcloud_gui(current_state())\n",
    "except topic_model_utility.TopicModelException as ex:\n",
    "    logger.info(ex)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color: green'>EXPLORE </span> pyLDAvis <span style='float: right; color: red'>TRY IT</span>\n",
    "http://www.aclweb.org/anthology/W14-3110 presented at the 2014 ACL Workshop on Interactive Language Learning, Visualization, and Interfaces in Baltimore on June 27, 2014.\n",
    "https://github.com/bmabey/pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el961222577423152169292870078\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el961222577423152169292870078_data = {\"mdsDat\": {\"x\": [0.1751889470503655, 0.190564350267717, 0.19317773238489033, -0.25009022606088777, -0.3088408036420851], \"y\": [0.10796225586522892, -0.03684297739244989, -0.10439905183486743, 0.3157907365869468, -0.2825109632248585], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [31.474641799926758, 28.534770965576172, 25.77131462097168, 8.23420238494873, 5.98507022857666]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"Freq\": [2492.0, 2241.0, 877.0, 1495.0, 756.0, 611.0, 2116.0, 672.0, 573.0, 1100.0, 773.0, 1033.0, 890.0, 889.0, 789.0, 798.0, 380.0, 702.0, 759.0, 701.0, 682.0, 614.0, 702.0, 691.0, 690.0, 272.0, 554.0, 530.0, 1075.0, 251.0, 691.4821166992188, 690.6885986328125, 702.51806640625, 561.4195556640625, 547.015869140625, 526.2782592773438, 472.6112365722656, 453.505615234375, 440.47320556640625, 415.9668273925781, 437.7976379394531, 395.3451843261719, 399.66790771484375, 408.8015441894531, 383.5866394042969, 410.6551818847656, 378.1744384765625, 371.2791442871094, 339.8663635253906, 351.7340393066406, 350.8044738769531, 337.3422546386719, 340.2524108886719, 340.130615234375, 339.4293212890625, 327.4382019042969, 322.7151184082031, 309.818603515625, 295.0033874511719, 283.0107727050781, 759.9563598632812, 825.8274536132812, 871.4600219726562, 660.6504516601562, 779.6492919921875, 623.843994140625, 1163.578369140625, 709.152099609375, 430.86724853515625, 515.0995483398438, 415.1296691894531, 369.887939453125, 1032.9371337890625, 890.5309448242188, 889.5468139648438, 759.532958984375, 798.2677001953125, 682.687744140625, 534.5, 548.2568359375, 521.5162963867188, 458.0941467285156, 483.7664794921875, 434.0478515625, 450.6893005371094, 395.2693786621094, 352.9671936035156, 328.6971130371094, 311.7130432128906, 327.295654296875, 325.06951904296875, 327.09539794921875, 315.5741882324219, 313.55810546875, 314.2954406738281, 283.26177978515625, 284.5799255371094, 285.94842529296875, 282.2824401855469, 264.40966796875, 279.9615478515625, 281.37078857421875, 279.7581481933594, 406.7445068359375, 648.3848876953125, 420.7795715332031, 677.4910278320312, 417.6238708496094, 448.741943359375, 603.5106201171875, 349.9830322265625, 498.98046875, 418.2427673339844, 383.8265075683594, 1495.4698486328125, 1100.431640625, 789.55859375, 701.166015625, 702.506591796875, 613.7837524414062, 554.2019653320312, 530.7122802734375, 400.86962890625, 405.2751770019531, 399.84124755859375, 283.33099365234375, 260.02581787109375, 251.3150634765625, 230.50978088378906, 219.16455078125, 213.05584716796875, 210.42535400390625, 181.4115447998047, 182.14584350585938, 186.504150390625, 186.92251586914062, 186.0147247314453, 173.1321563720703, 176.19357299804688, 179.36663818359375, 166.9002685546875, 169.98727416992188, 163.64263916015625, 160.34368896484375, 177.183349609375, 2045.833984375, 632.4695434570312, 365.1548156738281, 544.8154907226562, 376.6175537109375, 1616.8984375, 667.749267578125, 852.1891479492188, 266.6361389160156, 595.72412109375, 471.3277282714844, 737.8125, 297.3636779785156, 286.24859619140625, 395.1252136230469, 504.9612121582031, 323.9776611328125, 877.135009765625, 756.5071411132812, 671.8807983398438, 380.16839599609375, 234.8040008544922, 202.359375, 206.67242431640625, 192.6329803466797, 186.7104949951172, 171.99008178710938, 131.51446533203125, 134.10960388183594, 134.18759155273438, 133.42945861816406, 126.18936920166016, 125.1159896850586, 124.2602310180664, 111.89864349365234, 112.25528717041016, 106.66936492919922, 106.65726470947266, 104.29015350341797, 103.7025146484375, 97.47802734375, 104.44576263427734, 90.53754425048828, 77.08861541748047, 68.82926940917969, 59.325355529785156, 56.69444274902344, 59.39115905761719, 1328.2486572265625, 206.1977996826172, 113.88439178466797, 122.72737884521484, 91.90996551513672, 610.9374389648438, 573.237060546875, 272.0316162109375, 251.6788330078125, 232.002197265625, 240.97750854492188, 175.3416748046875, 150.03895568847656, 145.3452911376953, 145.6076202392578, 124.0541763305664, 134.5696563720703, 125.72549438476562, 108.15337371826172, 105.12022399902344, 84.25662231445312, 72.21701049804688, 65.1987075805664, 67.16044616699219, 64.75608825683594, 65.66397857666016, 59.438411712646484, 60.35396957397461, 53.145206451416016, 63.387088775634766, 45.67280578613281, 42.464107513427734, 43.220027923583984, 62.11567687988281, 49.11234664916992, 65.43148803710938, 82.61500549316406, 201.51161193847656, 148.46690368652344, 136.19778442382812, 320.8593444824219, 96.49583435058594, 99.97273254394531, 77.90849304199219, 99.44938659667969], \"Term\": [\"state\", \"field\", \"host\", \"people\", \"staff\", \"annex\", \"co-operation\", \"cost\", \"board\", \"science\", \"period\", \"member\", \"federal\", \"territory\", \"contact\", \"expert\", \"travel\", \"sport\", \"grant\", \"visit\", \"term\", \"information\", \"affairs\", \"participation\", \"understanding\", \"recommendation\", \"television\", \"organization\", \"programme\", \"child\", \"participation\", \"understanding\", \"affairs\", \"channel\", \"ratification\", \"instrument\", \"foreign\", \"plenipotentiary\", \"scholarship\", \"president\", \"place\", \"manner\", \"joint\", \"cooperation\", \"december\", \"minister\", \"june\", \"order\", \"writing\", \"professor\", \"notice\", \"association\", \"witness\", \"whereof\", \"history\", \"november\", \"iv\", \"seal\", \"learning\", \"citizen\", \"day\", \"representative\", \"programme\", \"material\", \"university\", \"book\", \"state\", \"implementation\", \"view\", \"commission\", \"national\", \"library\", \"member\", \"federal\", \"territory\", \"grant\", \"expert\", \"term\", \"appointment\", \"service\", \"centre\", \"support\", \"certificate\", \"council\", \"legislation\", \"convention\", \"archive\", \"regard\", \"collection\", \"ix\", \"iii\", \"viii\", \"xii\", \"xi\", \"vi\", \"xv\", \"xiv\", \"xiii\", \"secretary\", \"aim\", \"notification\", \"time\", \"personnel\", \"organisation\", \"establishment\", \"teacher\", \"commission\", \"course\", \"law\", \"research\", \"teaching\", \"co-operation\", \"university\", \"national\", \"people\", \"science\", \"contact\", \"visit\", \"sport\", \"information\", \"television\", \"organization\", \"press\", \"expense\", \"socialist\", \"academy\", \"museum\", \"friendship\", \"health\", \"technology\", \"journalist\", \"translation\", \"acquaintance\", \"house\", \"recognition\", \"sciences\", \"tourist\", \"new\", \"objective\", \"tie\", \"festival\", \"music\", \"republics\", \"matter\", \"medicine\", \"field\", \"work\", \"basis\", \"literature\", \"interest\", \"co-operation\", \"development\", \"education\", \"worker\", \"publication\", \"radio\", \"research\", \"artist\", \"lecture\", \"relation\", \"implementation\", \"establishment\", \"host\", \"staff\", \"cost\", \"travel\", \"use\", \"accommodation\", \"completion\", \"laboratory\", \"mission\", \"protocol\", \"reason\", \"security\", \"duration\", \"document\", \"curricula\", \"allowance\", \"payment\", \"fee\", \"transport\", \"importance\", \"city\", \"inter\", \"transfer\", \"level\", \"salary\", \"remuneration\", \"request\", \"researcher\", \"reimbursement\", \"account\", \"memorandum\", \"state\", \"authority\", \"event\", \"teaching\", \"provision\", \"annex\", \"board\", \"recommendation\", \"child\", \"living\", \"fields\", \"decision\", \"administration\", \"illness\", \"servant\", \"faculty\", \"paragraph\", \"post\", \"disposal\", \"transportation\", \"accident\", \"policy\", \"rate\", \"week\", \"receipt\", \"authorisation\", \"director\", \"hand\", \"letter\", \"death\", \"length\", \"guarantee\", \"supervision\", \"ground\", \"hospital\", \"pay\", \"disability\", \"tuition\", \"spouse\", \"compensation\", \"period\", \"repatriation\", \"leave\", \"architecture\", \"number\"], \"Total\": [2492.0, 2241.0, 877.0, 1495.0, 756.0, 611.0, 2116.0, 672.0, 573.0, 1100.0, 773.0, 1033.0, 890.0, 889.0, 789.0, 798.0, 380.0, 702.0, 759.0, 701.0, 682.0, 614.0, 702.0, 691.0, 690.0, 272.0, 554.0, 530.0, 1075.0, 251.0, 691.7014770507812, 690.9144897460938, 702.7498779296875, 561.6405639648438, 547.2469482421875, 526.5090942382812, 472.84283447265625, 453.7296142578125, 440.6990661621094, 416.18328857421875, 438.0267028808594, 395.5558166503906, 399.88507080078125, 409.02734375, 383.80133056640625, 410.88616943359375, 378.39239501953125, 371.5063781738281, 340.07489013671875, 351.95751953125, 351.03106689453125, 337.56231689453125, 340.47509765625, 340.353515625, 339.65234375, 327.6600646972656, 322.9381408691406, 310.0366516113281, 295.2179870605469, 283.22674560546875, 854.0474853515625, 955.9053955078125, 1075.9769287109375, 919.8772583007812, 1198.3731689453125, 886.2399291992188, 2492.391357421875, 1394.9393310546875, 568.9296264648438, 1193.06591796875, 799.4298706054688, 613.7247924804688, 1033.1636962890625, 890.7440185546875, 889.7798461914062, 759.744140625, 798.4921875, 682.9118041992188, 534.7006225585938, 548.4764404296875, 521.7389526367188, 458.29461669921875, 483.9806213378906, 434.2571105957031, 450.9090881347656, 395.49029541015625, 353.17938232421875, 328.9086608886719, 311.9166564941406, 327.51019287109375, 325.283203125, 327.3109130859375, 315.7854919433594, 313.7700500488281, 314.51123046875, 283.4648742675781, 284.784912109375, 286.1557922363281, 282.49285888671875, 264.6084899902344, 280.17523193359375, 281.591064453125, 279.98114013671875, 456.16595458984375, 972.8842163085938, 522.917724609375, 1193.06591796875, 600.9337158203125, 735.3709106445312, 1510.2789306640625, 473.1905517578125, 2116.457275390625, 1198.3731689453125, 799.4298706054688, 1495.7218017578125, 1100.6837158203125, 789.7993774414062, 701.4120483398438, 702.7536010742188, 614.0299682617188, 554.4496459960938, 530.9608764648438, 401.10137939453125, 405.5141906738281, 400.0892028808594, 283.5611877441406, 260.2621765136719, 251.54989624023438, 230.73745727539062, 219.39566040039062, 213.28353881835938, 210.6587677001953, 181.61532592773438, 182.35061645507812, 186.72898864746094, 187.14927673339844, 186.24114990234375, 173.34869384765625, 176.41659545898438, 179.5987548828125, 167.12867736816406, 170.22166442871094, 163.87933349609375, 160.5788116455078, 177.4873046875, 2241.88720703125, 695.5763549804688, 393.5574645996094, 613.261474609375, 407.62054443359375, 2116.457275390625, 834.6339111328125, 1298.1383056640625, 298.87213134765625, 881.182373046875, 668.401611328125, 1510.2789306640625, 386.3473815917969, 374.081298828125, 712.0062255859375, 1394.9393310546875, 972.8842163085938, 877.35693359375, 756.74267578125, 672.1129760742188, 380.4043884277344, 235.0341796875, 202.57127380371094, 206.89845275878906, 192.8526611328125, 186.95021057128906, 172.21878051757812, 131.72903442382812, 134.33021545410156, 134.4130859375, 133.65679931640625, 126.41281127929688, 125.34160614013672, 124.48759460449219, 112.11695098876953, 112.47509002685547, 106.89371490478516, 106.88502502441406, 104.51317596435547, 103.92870330810547, 97.71279907226562, 104.69738006591797, 90.76526641845703, 77.31757354736328, 69.0450439453125, 59.53666687011719, 56.91688919067383, 59.71334457397461, 2492.391357421875, 390.9812927246094, 242.10487365722656, 473.1905517578125, 399.1728210449219, 611.1184692382812, 573.4194946289062, 272.21282958984375, 251.8570556640625, 232.17535400390625, 241.16262817382812, 175.5243377685547, 150.21771240234375, 145.52711486816406, 145.79922485351562, 124.21981811523438, 134.75816345214844, 125.90225982666016, 108.33413696289062, 105.29922485351562, 84.4338607788086, 72.388916015625, 65.36954498291016, 67.34303283691406, 64.93218994140625, 65.8474349975586, 59.61602020263672, 60.5344352722168, 53.32813262939453, 63.62152862548828, 45.84367752075195, 42.628578186035156, 43.39445877075195, 62.36699676513672, 49.3211784362793, 65.73501586914062, 83.2439956665039, 206.576904296875, 158.19873046875, 150.81924438476562, 773.94775390625, 130.7928466796875, 162.66567993164062, 129.2881317138672, 351.68499755859375], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.1556999683380127, 1.1556999683380127, 1.1556999683380127, 1.1555999517440796, 1.1555999517440796, 1.155500054359436, 1.155500054359436, 1.155500054359436, 1.155500054359436, 1.155500054359436, 1.155500054359436, 1.155500054359436, 1.155400037765503, 1.155400037765503, 1.155400037765503, 1.155400037765503, 1.155400037765503, 1.155400037765503, 1.155400037765503, 1.155400037765503, 1.1553000211715698, 1.1553000211715698, 1.1553000211715698, 1.1553000211715698, 1.1553000211715698, 1.1553000211715698, 1.1553000211715698, 1.1553000211715698, 1.1553000211715698, 1.1552000045776367, 1.0392999649047852, 1.0096999406814575, 0.9452000260353088, 0.824999988079071, 0.7261000275611877, 0.8048999905586243, 0.39419999718666077, 0.4794999957084656, 0.878000020980835, 0.31610000133514404, 0.5006999969482422, 0.6496000289916992, 1.2538000345230103, 1.2538000345230103, 1.2538000345230103, 1.2538000345230103, 1.2538000345230103, 1.2537000179290771, 1.2537000179290771, 1.253600001335144, 1.253600001335144, 1.253600001335144, 1.253600001335144, 1.253600001335144, 1.253600001335144, 1.253499984741211, 1.2533999681472778, 1.2533999681472778, 1.2533999681472778, 1.2533999681472778, 1.2533999681472778, 1.2533999681472778, 1.2533999681472778, 1.2533999681472778, 1.2533999681472778, 1.2532999515533447, 1.2532999515533447, 1.2532999515533447, 1.2532999515533447, 1.2532999515533447, 1.2532999515533447, 1.2532999515533447, 1.2532000541687012, 1.1394000053405762, 0.8482999801635742, 1.0367000102996826, 0.6881999969482422, 0.8901000022888184, 0.7601000070571899, 0.3368000090122223, 0.9524000287055969, -0.19089999794960022, 0.2013999968767166, 0.5202999711036682, 1.3557000160217285, 1.3557000160217285, 1.3555999994277954, 1.3555999994277954, 1.3555999994277954, 1.3554999828338623, 1.3554999828338623, 1.3553999662399292, 1.355299949645996, 1.355299949645996, 1.355299949645996, 1.3551000356674194, 1.3550000190734863, 1.3550000190734863, 1.3549000024795532, 1.3549000024795532, 1.3547999858856201, 1.3547999858856201, 1.3547999858856201, 1.3547999858856201, 1.354699969291687, 1.354699969291687, 1.354699969291687, 1.354699969291687, 1.354599952697754, 1.354599952697754, 1.3545000553131104, 1.3545000553131104, 1.3545000553131104, 1.3544000387191772, 1.354200005531311, 1.2644000053405762, 1.2608000040054321, 1.281000018119812, 1.2375999689102173, 1.2768000364303589, 1.0866999626159668, 1.1327999830245972, 0.9350000023841858, 1.2417999505996704, 0.9643999934196472, 1.006600022315979, 0.6395000219345093, 1.094099998474121, 1.0882999897003174, 0.7670000195503235, 0.33980000019073486, 0.2563000023365021, 2.4965999126434326, 2.4965999126434326, 2.496500015258789, 2.496299982070923, 2.4958999156951904, 2.495800018310547, 2.495800018310547, 2.495699882507324, 2.4955999851226807, 2.495500087738037, 2.4951999187469482, 2.4951999187469482, 2.4951999187469482, 2.4951999187469482, 2.4951000213623047, 2.4951000213623047, 2.494999885559082, 2.4948999881744385, 2.4948999881744385, 2.494800090789795, 2.4946999549865723, 2.4946999549865723, 2.4946999549865723, 2.494499921798706, 2.494499921798706, 2.4944000244140625, 2.4939000606536865, 2.4937000274658203, 2.493299961090088, 2.493000030517578, 2.491499900817871, 1.8674999475479126, 1.8569999933242798, 1.7426999807357788, 1.1473000049591064, 1.0283000469207764, 2.8155999183654785, 2.8155999183654785, 2.815200090408325, 2.815200090408325, 2.815200090408325, 2.8150999546051025, 2.8148999214172363, 2.81469988822937, 2.81469988822937, 2.8145999908447266, 2.8145999908447266, 2.814500093460083, 2.814500093460083, 2.814199924468994, 2.814199924468994, 2.813800096511841, 2.813499927520752, 2.8132998943328857, 2.813199996948242, 2.813199996948242, 2.8131000995635986, 2.8129000663757324, 2.8129000663757324, 2.8125, 2.8122000694274902, 2.8122000694274902, 2.812000036239624, 2.8118999004364014, 2.8118999004364014, 2.8117001056671143, 2.811300039291382, 2.808300018310547, 2.791100025177002, 2.7523999214172363, 2.713900089263916, 1.9354000091552734, 2.5118000507354736, 2.3290998935699463, 2.3094000816345215, 1.5528000593185425], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -4.0167999267578125, -4.01800012588501, -4.000999927520752, -4.225200176239014, -4.251200199127197, -4.28980016708374, -4.39739990234375, -4.438600063323975, -4.467800140380859, -4.525000095367432, -4.473899841308594, -4.575900077819824, -4.565000057220459, -4.542399883270264, -4.606100082397461, -4.537899971008301, -4.620299816131592, -4.638700008392334, -4.727099895477295, -4.692800045013428, -4.695400238037109, -4.734499931335449, -4.72599983215332, -4.72629976272583, -4.728400230407715, -4.7642998695373535, -4.778900146484375, -4.819699764251709, -4.86870002746582, -4.910200119018555, -3.9223999977111816, -3.8392999172210693, -3.7855000495910645, -4.062399864196777, -3.8968000411987305, -4.119699954986572, -3.4964001178741455, -3.9916000366210938, -4.489799976348877, -4.311299800872803, -4.5269999504089355, -4.642399787902832, -3.517400026321411, -3.665800094604492, -3.6668999195098877, -3.824899911880493, -3.775099992752075, -3.93149995803833, -4.176300048828125, -4.1508002281188965, -4.200799942016602, -4.33050012588501, -4.276000022888184, -4.384399890899658, -4.346799850463867, -4.478000164031982, -4.59119987487793, -4.662399768829346, -4.7154998779296875, -4.6666998863220215, -4.673500061035156, -4.667300224304199, -4.703199863433838, -4.70959997177124, -4.707200050354004, -4.811200141906738, -4.806600093841553, -4.801799774169922, -4.814700126647949, -4.880099773406982, -4.82289981842041, -4.81790018081665, -4.823699951171875, -4.449399948120117, -3.983099937438965, -4.415500164031982, -3.939199924468994, -4.422999858856201, -4.351099967956543, -4.054800033569336, -4.599699974060059, -4.244999885559082, -4.421500205993652, -4.507400035858154, -3.0455000400543213, -3.352299928665161, -3.6842000484466553, -3.802999973297119, -3.801100015640259, -3.9361000061035156, -4.0381999015808105, -4.081500053405762, -4.362100124359131, -4.351200103759766, -4.364699840545654, -4.709099769592285, -4.794899940490723, -4.828999996185303, -4.91540002822876, -4.96589994430542, -4.994200229644775, -5.0065999031066895, -5.15500020980835, -5.150899887084961, -5.127299785614014, -5.125, -5.129899978637695, -5.201700210571289, -5.184100151062012, -5.166299819946289, -5.23829984664917, -5.21999979019165, -5.257999897003174, -5.27839994430542, -5.178500175476074, -2.7321999073028564, -3.906100034713745, -4.455399990081787, -4.055300235748291, -4.424499988555908, -2.9674999713897705, -3.851799964904785, -3.6078999042510986, -4.769800186157227, -3.96589994430542, -4.200200080871582, -3.752000093460083, -4.660799980163574, -4.69890022277832, -4.376500129699707, -4.131199836730957, -4.574999809265137, -2.4381000995635986, -2.5859999656677246, -2.704699993133545, -3.2741000652313232, -3.75600004196167, -3.9047000408172607, -3.8835999965667725, -3.9539999961853027, -3.9851999282836914, -4.067299842834473, -4.335599899291992, -4.316100120544434, -4.315499782562256, -4.321199893951416, -4.376999855041504, -4.385499954223633, -4.392399787902832, -4.497200012207031, -4.49399995803833, -4.545000076293945, -4.545100212097168, -4.567599773406982, -4.573200225830078, -4.6350998878479, -4.566100120544434, -4.709000110626221, -4.869800090789795, -4.983099937438965, -5.131700038909912, -5.17710018157959, -5.1305999755859375, -2.023099899291992, -3.8859000205993652, -4.479599952697754, -4.404799938201904, -4.693900108337402, -2.4807000160217285, -2.5443999767303467, -3.289799928665161, -3.3675999641418457, -3.4489998817443848, -3.4110000133514404, -3.7290000915527344, -3.8847999572753906, -3.916599988937378, -3.914799928665161, -4.074999809265137, -3.9935998916625977, -4.061600208282471, -4.212200164794922, -4.240600109100342, -4.461900234222412, -4.616099834442139, -4.718299865722656, -4.688600063323975, -4.725100040435791, -4.71120023727417, -4.810800075531006, -4.795499801635742, -4.922699928283691, -4.746500015258789, -5.07420015335083, -5.14709997177124, -5.12939977645874, -4.76669979095459, -5.0015997886657715, -4.714700222015381, -4.481500148773193, -3.589900016784668, -3.895400047302246, -3.981600046157837, -3.1247000694274902, -4.326200008392334, -4.290800094604492, -4.540200233459473, -4.29610013961792]}, \"token.table\": {\"Topic\": [3, 5, 4, 4, 3, 5, 1, 2, 4, 5, 2, 3, 5, 2, 1, 3, 1, 5, 1, 2, 4, 3, 4, 5, 1, 2, 3, 2, 2, 1, 5, 1, 4, 2, 3, 2, 1, 2, 4, 5, 4, 3, 2, 1, 4, 2, 1, 2, 4, 4, 1, 2, 5, 1, 5, 1, 2, 3, 4, 5, 5, 5, 5, 4, 4, 1, 2, 3, 4, 5, 2, 3, 1, 3, 4, 3, 2, 5, 2, 4, 3, 2, 3, 5, 1, 3, 2, 5, 5, 5, 3, 1, 5, 4, 3, 2, 5, 1, 2, 3, 5, 4, 3, 1, 4, 3, 4, 1, 2, 1, 3, 1, 4, 1, 2, 1, 4, 5, 1, 3, 2, 5, 5, 4, 1, 2, 3, 1, 2, 3, 5, 1, 1, 2, 3, 3, 2, 4, 1, 4, 3, 3, 1, 2, 3, 1, 2, 1, 2, 5, 3, 1, 2, 3, 3, 5, 1, 5, 4, 3, 1, 2, 3, 4, 5, 2, 1, 1, 5, 5, 1, 3, 1, 1, 3, 4, 1, 2, 4, 5, 1, 3, 1, 2, 3, 5, 1, 4, 5, 3, 5, 2, 4, 1, 3, 4, 4, 5, 1, 3, 3, 4, 1, 2, 3, 5, 4, 4, 1, 3, 3, 1, 2, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 5, 2, 2, 3, 2, 4, 3, 3, 2, 2, 3, 2, 3, 4, 3, 4, 5, 4, 3, 4, 5, 1, 1, 2, 4, 2, 1, 2, 2, 3, 5, 1, 1, 1, 3, 4, 2, 3, 1, 2, 2, 2, 2, 2], \"Freq\": [0.9980209469795227, 0.9948615431785583, 0.9971798658370972, 1.0014601945877075, 0.9966119527816772, 0.9985507130622864, 1.0003559589385986, 0.9977003931999207, 0.9972745776176453, 0.9998061656951904, 0.9986897110939026, 0.3944677710533142, 0.6033036112785339, 0.9994921088218689, 0.2303626388311386, 0.7687382102012634, 0.9983341693878174, 1.002316951751709, 0.05371100828051567, 0.41689974069595337, 0.5268794298171997, 0.9274376034736633, 0.07114589959383011, 0.9992684125900269, 0.7040982842445374, 0.1252482533454895, 0.17038275301456451, 1.0005003213882446, 1.000040054321289, 0.9988594651222229, 1.0005675554275513, 0.9991994500160217, 1.0010757446289062, 0.23577135801315308, 0.7640125751495361, 1.0002671480178833, 0.4316609799861908, 0.5674455761909485, 0.09282635152339935, 0.9017416834831238, 1.0004907846450806, 1.0002540349960327, 0.9987602829933167, 0.999933123588562, 0.9998319149017334, 0.999407947063446, 0.27623680233955383, 0.6955841779708862, 0.0282893106341362, 0.9967344403266907, 0.8898802399635315, 0.11006413400173187, 0.9902308583259583, 1.0005176067352295, 0.997012734413147, 0.056312114000320435, 0.09105788916349411, 0.8003509044647217, 0.050321463495492935, 0.0011981300776824355, 0.9896668791770935, 0.9970688819885254, 0.9969156980514526, 0.9950859546661377, 0.9969267249107361, 0.12864576280117035, 0.21415284276008606, 0.6563245058059692, 0.0007703339215368032, 0.0007703339215368032, 0.666060745716095, 0.3330303728580475, 0.38000062108039856, 0.14869588613510132, 0.47087031602859497, 0.9987320303916931, 0.9993836283683777, 0.9982303977012634, 1.000287413597107, 0.9989568591117859, 0.9992300868034363, 0.08742634207010269, 0.912623941898346, 0.9993256330490112, 1.0003323554992676, 0.9978139400482178, 1.000336766242981, 0.9941155314445496, 0.9852545261383057, 0.9911713600158691, 1.0011378526687622, 0.9980793595314026, 0.9934880137443542, 0.999593198299408, 0.9980772137641907, 0.9991293549537659, 0.9963778853416443, 0.5082658529281616, 0.12903787195682526, 0.36202290654182434, 0.0007168770534917712, 1.000994324684143, 0.999951183795929, 0.9990330934524536, 0.9950898289680481, 0.924879789352417, 0.07605112344026566, 1.000191569328308, 0.9984422326087952, 1.000287413597107, 0.9986705780029297, 0.9989629983901978, 1.000764012336731, 0.3889193832874298, 0.6105762124061584, 0.9992616176605225, 0.38114985823631287, 0.6147578358650208, 0.23256976902484894, 0.7645397186279297, 1.0002015829086304, 1.0034098625183105, 0.9938468933105469, 0.9927051663398743, 0.6028760671615601, 0.24277983605861664, 0.1531631201505661, 0.07990066707134247, 0.030981890857219696, 0.8886910676956177, 0.999244749546051, 0.9985948204994202, 0.7185741066932678, 0.2815592885017395, 0.996395468711853, 0.9972544312477112, 0.999841570854187, 0.9880538582801819, 1.000277042388916, 1.0002663135528564, 0.9989926218986511, 0.998697817325592, 0.5191199779510498, 0.4803423285484314, 0.9979884624481201, 0.9999114871025085, 0.9993745684623718, 0.9979855418205261, 0.716550350189209, 0.2815019190311432, 0.9976385831832886, 0.9986369609832764, 0.8922191262245178, 0.1074170470237732, 1.0000736713409424, 1.0017945766448975, 0.9989858865737915, 0.9888185262680054, 0.9960831999778748, 0.9995174407958984, 0.10336615145206451, 0.16280168294906616, 0.316558837890625, 0.002584153786301613, 0.4147566854953766, 1.0000673532485962, 0.9999390244483948, 1.0005959272384644, 0.9946274161338806, 1.0007762908935547, 0.9995595812797546, 0.9997472763061523, 1.0001206398010254, 0.8094969391822815, 0.18959514796733856, 0.9987296462059021, 0.08267095685005188, 0.683914303779602, 0.23047661781311035, 0.0025051806587725878, 0.32342907786369324, 0.6763639450073242, 0.18402110040187836, 0.10921577364206314, 0.7046661376953125, 0.9943468570709229, 0.9995487332344055, 1.0020569562911987, 1.0010442733764648, 1.0014513731002808, 0.9992181658744812, 1.0002777576446533, 0.9909859299659729, 0.44381633400917053, 0.5547704100608826, 1.0025861263275146, 0.2599530518054962, 0.7339850664138794, 0.8641022443771362, 0.1359967142343521, 1.0007363557815552, 0.9958925843238831, 0.11123772710561752, 0.3999261260032654, 0.48865145444869995, 0.0006621293723583221, 0.9993476271629333, 0.9933390617370605, 0.9984137415885925, 0.9993788003921509, 0.9992023706436157, 0.9998818039894104, 0.9982553124427795, 0.9975417852401733, 1.0013771057128906, 0.9991313219070435, 0.9997770190238953, 1.0003505945205688, 0.056890469044446945, 0.9355321526527405, 1.0003399848937988, 0.4670213460922241, 0.5328215956687927, 0.9909099340438843, 0.9993571639060974, 0.8050979971885681, 0.19505935907363892, 0.7396597266197205, 0.2599375545978546, 0.9981966018676758, 0.999189019203186, 1.0001291036605835, 1.0002474784851074, 0.9966661334037781, 0.9979009628295898, 0.9987051486968994, 1.0006860494613647, 0.9968728423118591, 0.9957760572433472, 0.9971583485603333, 0.9989369511604309, 0.009681624360382557, 0.014522437006235123, 0.9778440594673157, 1.0001237392425537, 0.6508824229240417, 0.3488062024116516, 0.999854564666748, 0.9983745217323303, 0.7575629353523254, 0.2425607591867447, 0.9990500807762146, 0.9994125366210938, 0.9949061870574951, 0.998961329460144, 0.9986045956611633, 0.05319329723715782, 0.9085990190505981, 0.03737907484173775, 0.10706920176744461, 0.8933586478233337, 0.9997797608375549, 1.0007328987121582, 1.0006792545318604, 0.9994555711746216, 1.0007553100585938, 0.9983600378036499], \"Term\": [\"academy\", \"accident\", \"accommodation\", \"account\", \"acquaintance\", \"administration\", \"affairs\", \"aim\", \"allowance\", \"annex\", \"appointment\", \"architecture\", \"architecture\", \"archive\", \"artist\", \"artist\", \"association\", \"authorisation\", \"authority\", \"authority\", \"authority\", \"basis\", \"basis\", \"board\", \"book\", \"book\", \"book\", \"centre\", \"certificate\", \"channel\", \"child\", \"citizen\", \"city\", \"co-operation\", \"co-operation\", \"collection\", \"commission\", \"commission\", \"compensation\", \"compensation\", \"completion\", \"contact\", \"convention\", \"cooperation\", \"cost\", \"council\", \"course\", \"course\", \"course\", \"curricula\", \"day\", \"day\", \"death\", \"december\", \"decision\", \"development\", \"development\", \"development\", \"development\", \"development\", \"director\", \"disability\", \"disposal\", \"document\", \"duration\", \"education\", \"education\", \"education\", \"education\", \"education\", \"establishment\", \"establishment\", \"event\", \"event\", \"event\", \"expense\", \"expert\", \"faculty\", \"federal\", \"fee\", \"festival\", \"field\", \"field\", \"fields\", \"foreign\", \"friendship\", \"grant\", \"ground\", \"guarantee\", \"hand\", \"health\", \"history\", \"hospital\", \"host\", \"house\", \"iii\", \"illness\", \"implementation\", \"implementation\", \"implementation\", \"implementation\", \"importance\", \"information\", \"instrument\", \"inter\", \"interest\", \"interest\", \"iv\", \"ix\", \"joint\", \"journalist\", \"june\", \"laboratory\", \"law\", \"law\", \"learning\", \"leave\", \"leave\", \"lecture\", \"lecture\", \"legislation\", \"length\", \"letter\", \"level\", \"library\", \"library\", \"library\", \"literature\", \"literature\", \"literature\", \"living\", \"manner\", \"material\", \"material\", \"matter\", \"medicine\", \"member\", \"memorandum\", \"minister\", \"mission\", \"museum\", \"music\", \"national\", \"national\", \"new\", \"notice\", \"notification\", \"november\", \"number\", \"number\", \"objective\", \"order\", \"organisation\", \"organisation\", \"organization\", \"paragraph\", \"participation\", \"pay\", \"payment\", \"people\", \"period\", \"period\", \"period\", \"period\", \"period\", \"personnel\", \"place\", \"plenipotentiary\", \"policy\", \"post\", \"president\", \"press\", \"professor\", \"programme\", \"programme\", \"protocol\", \"provision\", \"provision\", \"provision\", \"provision\", \"publication\", \"publication\", \"radio\", \"radio\", \"radio\", \"rate\", \"ratification\", \"reason\", \"receipt\", \"recognition\", \"recommendation\", \"regard\", \"reimbursement\", \"relation\", \"relation\", \"remuneration\", \"repatriation\", \"repatriation\", \"representative\", \"representative\", \"republics\", \"request\", \"research\", \"research\", \"research\", \"research\", \"researcher\", \"salary\", \"scholarship\", \"science\", \"sciences\", \"seal\", \"secretary\", \"security\", \"servant\", \"service\", \"socialist\", \"sport\", \"spouse\", \"spouse\", \"staff\", \"state\", \"state\", \"supervision\", \"support\", \"teacher\", \"teacher\", \"teaching\", \"teaching\", \"technology\", \"television\", \"term\", \"territory\", \"tie\", \"time\", \"tourist\", \"transfer\", \"translation\", \"transport\", \"transportation\", \"travel\", \"tuition\", \"tuition\", \"tuition\", \"understanding\", \"university\", \"university\", \"use\", \"vi\", \"view\", \"view\", \"viii\", \"visit\", \"week\", \"whereof\", \"witness\", \"work\", \"work\", \"work\", \"worker\", \"worker\", \"writing\", \"xi\", \"xii\", \"xiii\", \"xiv\", \"xv\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [5, 4, 2, 1, 3]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el961222577423152169292870078\", ldavis_el961222577423152169292870078_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el961222577423152169292870078\", ldavis_el961222577423152169292870078_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el961222577423152169292870078\", ldavis_el961222577423152169292870078_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=       x         y         topics  cluster  Freq     \n",
       "topic                                                \n",
       "4      0.175189  0.107962  1       1        31.474642\n",
       "3      0.190564 -0.036843  2       1        28.534771\n",
       "1      0.193178 -0.104399  3       1        25.771315\n",
       "0     -0.250090  0.315791  4       1         8.234202\n",
       "2     -0.308841 -0.282511  5       1         5.985070, topic_info=     Category  Freq        Term              Total        loglift  logprob\n",
       "term                                                                      \n",
       "147   Default  2492.000000            state  2492.000000  30.0000  30.0000\n",
       "59    Default  2241.000000            field  2241.000000  29.0000  29.0000\n",
       "1149  Default   877.000000             host   877.000000  28.0000  28.0000\n",
       "108   Default  1495.000000           people  1495.000000  27.0000  27.0000\n",
       "800   Default   756.000000            staff   756.000000  26.0000  26.0000\n",
       "169   Default   611.000000            annex   611.000000  25.0000  25.0000\n",
       "30    Default  2116.000000     co-operation  2116.000000  24.0000  24.0000\n",
       "750   Default   672.000000             cost   672.000000  23.0000  23.0000\n",
       "475   Default   573.000000            board   573.000000  22.0000  22.0000\n",
       "141   Default  1100.000000          science  1100.000000  21.0000  21.0000\n",
       "109   Default   773.000000           period   773.000000  20.0000  20.0000\n",
       "93    Default  1033.000000           member  1033.000000  19.0000  19.0000\n",
       "273   Default   890.000000          federal   890.000000  18.0000  18.0000\n",
       "230   Default   889.000000        territory   889.000000  17.0000  17.0000\n",
       "37    Default   789.000000          contact   789.000000  16.0000  16.0000\n",
       "271   Default   798.000000           expert   798.000000  15.0000  15.0000\n",
       "155   Default   380.000000           travel   380.000000  14.0000  14.0000\n",
       "496   Default   702.000000            sport   702.000000  13.0000  13.0000\n",
       "405   Default   759.000000            grant   759.000000  12.0000  12.0000\n",
       "234   Default   701.000000            visit   701.000000  11.0000  11.0000\n",
       "325   Default   682.000000             term   682.000000  10.0000  10.0000\n",
       "283   Default   614.000000      information   614.000000   9.0000   9.0000\n",
       "239   Default   702.000000          affairs   702.000000   8.0000   8.0000\n",
       "974   Default   691.000000    participation   691.000000   7.0000   7.0000\n",
       "157   Default   690.000000    understanding   690.000000   6.0000   6.0000\n",
       "128   Default   272.000000   recommendation   272.000000   5.0000   5.0000\n",
       "1102  Default   554.000000       television   554.000000   4.0000   4.0000\n",
       "297   Default   530.000000     organization   530.000000   3.0000   3.0000\n",
       "216   Default  1075.000000        programme  1075.000000   2.0000   2.0000\n",
       "828   Default   251.000000            child   251.000000   1.0000   1.0000\n",
       "974    Topic1   691.482117    participation   691.701477   1.1557  -4.0168\n",
       "157    Topic1   690.688599    understanding   690.914490   1.1557  -4.0180\n",
       "239    Topic1   702.518066          affairs   702.749878   1.1557  -4.0010\n",
       "22     Topic1   561.419556          channel   561.640564   1.1556  -4.2252\n",
       "310    Topic1   547.015869     ratification   547.246948   1.1556  -4.2512\n",
       "284    Topic1   526.278259       instrument   526.509094   1.1555  -4.2898\n",
       "275    Topic1   472.611237          foreign   472.842834   1.1555  -4.3974\n",
       "213    Topic1   453.505615  plenipotentiary   453.729614   1.1555  -4.4386\n",
       "139    Topic1   440.473206      scholarship   440.699066   1.1555  -4.4678\n",
       "305    Topic1   415.966827        president   416.183289   1.1555  -4.5250\n",
       "212    Topic1   437.797638            place   438.026703   1.1555  -4.4739\n",
       "88     Topic1   395.345184           manner   395.555817   1.1555  -4.5759\n",
       "198    Topic1   399.667908            joint   399.885071   1.1554  -4.5650\n",
       "657    Topic1   408.801544      cooperation   409.027344   1.1554  -4.5424\n",
       "40     Topic1   383.586639         december   383.801331   1.1554  -4.6061\n",
       "95     Topic1   410.655182         minister   410.886169   1.1554  -4.5379\n",
       "199    Topic1   378.174438             june   378.392395   1.1554  -4.6203\n",
       "105    Topic1   371.279144            order   371.506378   1.1554  -4.6387\n",
       "1065   Topic1   339.866364          writing   340.074890   1.1554  -4.7271\n",
       "117    Topic1   351.734039        professor   351.957520   1.1554  -4.6928\n",
       "368    Topic1   350.804474           notice   351.031067   1.1553  -4.6954\n",
       "247    Topic1   337.342255      association   337.562317   1.1553  -4.7345\n",
       "382    Topic1   340.252411          witness   340.475098   1.1553  -4.7260\n",
       "235    Topic1   340.130615          whereof   340.353516   1.1553  -4.7263\n",
       "66     Topic1   339.429321          history   339.652344   1.1553  -4.7284\n",
       "465    Topic1   327.438202         november   327.660065   1.1553  -4.7643\n",
       "76     Topic1   322.715118               iv   322.938141   1.1553  -4.7789\n",
       "225    Topic1   309.818604             seal   310.036652   1.1553  -4.8197\n",
       "418    Topic1   295.003387         learning   295.217987   1.1553  -4.8687\n",
       "255    Topic1   283.010773          citizen   283.226746   1.1552  -4.9102\n",
       "264    Topic1   759.956360              day   854.047485   1.0393  -3.9224\n",
       "220    Topic1   825.827454   representative   955.905396   1.0097  -3.8393\n",
       "216    Topic1   871.460022        programme  1075.976929   0.9452  -3.7855\n",
       "486    Topic1   660.650452         material   919.877258   0.8250  -4.0624\n",
       "159    Topic1   779.649292       university  1198.373169   0.7261  -3.8968\n",
       "13     Topic1   623.843994             book   886.239929   0.8049  -4.1197\n",
       "147    Topic1  1163.578369            state  2492.391357   0.3942  -3.4964\n",
       "70     Topic1   709.152100   implementation  1394.939331   0.4795  -3.9916\n",
       "233    Topic1   430.867249             view   568.929626   0.8780  -4.4898\n",
       "33     Topic1   515.099548       commission  1193.065918   0.3161  -4.3113\n",
       "97     Topic1   415.129669         national   799.429871   0.5007  -4.5270\n",
       "81     Topic1   369.887939          library   613.724792   0.6496  -4.6424\n",
       "93     Topic2  1032.937134           member  1033.163696   1.2538  -3.5174\n",
       "273    Topic2   890.530945          federal   890.744019   1.2538  -3.6658\n",
       "230    Topic2   889.546814        territory   889.779846   1.2538  -3.6669\n",
       "405    Topic2   759.532959            grant   759.744141   1.2538  -3.8249\n",
       "271    Topic2   798.267700           expert   798.492188   1.2538  -3.7751\n",
       "325    Topic2   682.687744             term   682.911804   1.2537  -3.9315\n",
       "812    Topic2   534.500000      appointment   534.700623   1.2537  -4.1763\n",
       "595    Topic2   548.256836          service   548.476440   1.2536  -4.1508\n",
       "252    Topic2   521.516296           centre   521.738953   1.2536  -4.2008\n",
       "548    Topic2   458.094147          support   458.294617   1.2536  -4.3305\n",
       "390    Topic2   483.766479      certificate   483.980621   1.2536  -4.2760\n",
       "478    Topic2   434.047852          council   434.257111   1.2536  -4.3844\n",
       "200    Topic2   450.689301      legislation   450.909088   1.2536  -4.3468\n",
       "182    Topic2   395.269379       convention   395.490295   1.2535  -4.4780\n",
       "505    Topic2   352.967194          archive   353.179382   1.2534  -4.5912\n",
       "218    Topic2   328.697113           regard   328.908661   1.2534  -4.6624\n",
       "32     Topic2   311.713043       collection   311.916656   1.2534  -4.7155\n",
       "526    Topic2   327.295654               ix   327.510193   1.2534  -4.6667\n",
       "522    Topic2   325.069519              iii   325.283203   1.2534  -4.6735\n",
       "556    Topic2   327.095398             viii   327.310913   1.2534  -4.6673\n",
       "562    Topic2   315.574188              xii   315.785492   1.2534  -4.7032\n",
       "561    Topic2   313.558105               xi   313.770050   1.2534  -4.7096\n",
       "331    Topic2   314.295441               vi   314.511230   1.2534  -4.7072\n",
       "566    Topic2   283.261780               xv   283.464874   1.2533  -4.8112\n",
       "564    Topic2   284.579926              xiv   284.784912   1.2533  -4.8066\n",
       "563    Topic2   285.948425             xiii   286.155792   1.2533  -4.8018\n",
       "692    Topic2   282.282440        secretary   282.492859   1.2533  -4.8147\n",
       "241    Topic2   264.409668              aim   264.608490   1.2533  -4.8801\n",
       "369    Topic2   279.961548     notification   280.175232   1.2533  -4.8229\n",
       "596    Topic2   281.370789             time   281.591064   1.2533  -4.8179\n",
       "374    Topic2   279.758148        personnel   279.981140   1.2532  -4.8237\n",
       "106    Topic2   406.744507     organisation   456.165955   1.1394  -4.4494\n",
       "57     Topic2   648.384888    establishment   972.884216   0.8483  -3.9831\n",
       "152    Topic2   420.779572          teacher   522.917725   1.0367  -4.4155\n",
       "33     Topic2   677.491028       commission  1193.065918   0.6882  -3.9392\n",
       "38     Topic2   417.623871           course   600.933716   0.8901  -4.4230\n",
       "361    Topic2   448.741943              law   735.370911   0.7601  -4.3511\n",
       "221    Topic2   603.510620         research  1510.278931   0.3368  -4.0548\n",
       "806    Topic2   349.983032         teaching   473.190552   0.9524  -4.5997\n",
       "30     Topic2   498.980469     co-operation  2116.457275  -0.1909  -4.2450\n",
       "159    Topic2   418.242767       university  1198.373169   0.2014  -4.4215\n",
       "97     Topic2   383.826508         national   799.429871   0.5203  -4.5074\n",
       "108    Topic3  1495.469849           people  1495.721802   1.3557  -3.0455\n",
       "141    Topic3  1100.431641          science  1100.683716   1.3557  -3.3523\n",
       "37     Topic3   789.558594          contact   789.799377   1.3556  -3.6842\n",
       "234    Topic3   701.166016            visit   701.412048   1.3556  -3.8030\n",
       "496    Topic3   702.506592            sport   702.753601   1.3556  -3.8011\n",
       "283    Topic3   613.783752      information   614.029968   1.3555  -3.9361\n",
       "1102   Topic3   554.201965       television   554.449646   1.3555  -4.0382\n",
       "297    Topic3   530.712280     organization   530.960876   1.3554  -4.0815\n",
       "306    Topic3   400.869629            press   401.101379   1.3553  -4.3621\n",
       "270    Topic3   405.275177          expense   405.514191   1.3553  -4.3512\n",
       "1697   Topic3   399.841248        socialist   400.089203   1.3553  -4.3647\n",
       "471    Topic3   283.330994          academy   283.561188   1.3551  -4.7091\n",
       "531    Topic3   260.025818           museum   260.262177   1.3550  -4.7949\n",
       "519    Topic3   251.315063       friendship   251.549896   1.3550  -4.8290\n",
       "280    Topic3   230.509781           health   230.737457   1.3549  -4.9154\n",
       "1738   Topic3   219.164551       technology   219.395660   1.3549  -4.9659\n",
       "285    Topic3   213.055847       journalist   213.283539   1.3548  -4.9942\n",
       "327    Topic3   210.425354      translation   210.658768   1.3548  -5.0066\n",
       "236    Topic3   181.411545     acquaintance   181.615326   1.3548  -5.1550\n",
       "834    Topic3   182.145844            house   182.350616   1.3548  -5.1509\n",
       "493    Topic3   186.504150      recognition   186.728989   1.3547  -5.1273\n",
       "468    Topic3   186.922516         sciences   187.149277   1.3547  -5.1250\n",
       "597    Topic3   186.014725          tourist   186.241150   1.3547  -5.1299\n",
       "1228   Topic3   173.132156              new   173.348694   1.3547  -5.2017\n",
       "660    Topic3   176.193573        objective   176.416595   1.3546  -5.1841\n",
       "732    Topic3   179.366638              tie   179.598755   1.3546  -5.1663\n",
       "1708   Topic3   166.900269         festival   167.128677   1.3545  -5.2383\n",
       "613    Topic3   169.987274            music   170.221664   1.3545  -5.2200\n",
       "1696   Topic3   163.642639        republics   163.879333   1.3545  -5.2580\n",
       "610    Topic3   160.343689           matter   160.578812   1.3544  -5.2784\n",
       "2440   Topic3   177.183350         medicine   177.487305   1.3542  -5.1785\n",
       "59     Topic3  2045.833984            field  2241.887207   1.2644  -2.7322\n",
       "163    Topic3   632.469543             work   695.576355   1.2608  -3.9061\n",
       "9      Topic3   365.154816            basis   393.557465   1.2810  -4.4554\n",
       "85     Topic3   544.815491       literature   613.261475   1.2376  -4.0553\n",
       "74     Topic3   376.617554         interest   407.620544   1.2768  -4.4245\n",
       "30     Topic3  1616.898438     co-operation  2116.457275   1.0867  -2.9675\n",
       "46     Topic3   667.749268      development   834.633911   1.1328  -3.8518\n",
       "53     Topic3   852.189148        education  1298.138306   0.9350  -3.6079\n",
       "334    Topic3   266.636139           worker   298.872131   1.2418  -4.7698\n",
       "123    Topic3   595.724121      publication   881.182373   0.9644  -3.9659\n",
       "126    Topic3   471.327728            radio   668.401611   1.0066  -4.2002\n",
       "221    Topic3   737.812500         research  1510.278931   0.6395  -3.7520\n",
       "171    Topic3   297.363678           artist   386.347382   1.0941  -4.6608\n",
       "79     Topic3   286.248596          lecture   374.081299   1.0883  -4.6989\n",
       "132    Topic3   395.125214         relation   712.006226   0.7670  -4.3765\n",
       "70     Topic3   504.961212   implementation  1394.939331   0.3398  -4.1312\n",
       "57     Topic3   323.977661    establishment   972.884216   0.2563  -4.5750\n",
       "1149   Topic4   877.135010             host   877.356934   2.4966  -2.4381\n",
       "800    Topic4   756.507141            staff   756.742676   2.4966  -2.5860\n",
       "750    Topic4   671.880798             cost   672.112976   2.4965  -2.7047\n",
       "155    Topic4   380.168396           travel   380.404388   2.4963  -3.2741\n",
       "160    Topic4   234.804001              use   235.034180   2.4959  -3.7560\n",
       "1699   Topic4   202.359375    accommodation   202.571274   2.4958  -3.9047\n",
       "906    Topic4   206.672424       completion   206.898453   2.4958  -3.8836\n",
       "78     Topic4   192.632980       laboratory   192.852661   2.4957  -3.9540\n",
       "780    Topic4   186.710495          mission   186.950211   2.4956  -3.9852\n",
       "120    Topic4   171.990082         protocol   172.218781   2.4955  -4.0673\n",
       "2163   Topic4   131.514465           reason   131.729034   2.4952  -4.3356\n",
       "226    Topic4   134.109604         security   134.330215   2.4952  -4.3161\n",
       "186    Topic4   134.187592         duration   134.413086   2.4952  -4.3155\n",
       "754    Topic4   133.429459         document   133.656799   2.4952  -4.3212\n",
       "631    Topic4   126.189369        curricula   126.412811   2.4951  -4.3770\n",
       "1411   Topic4   125.115990        allowance   125.341606   2.4951  -4.3855\n",
       "787    Topic4   124.260231          payment   124.487595   2.4950  -4.3924\n",
       "857    Topic4   111.898643              fee   112.116951   2.4949  -4.4972\n",
       "810    Topic4   112.255287        transport   112.475090   2.4949  -4.4940\n",
       "767    Topic4   106.669365       importance   106.893715   2.4948  -4.5450\n",
       "25     Topic4   106.657265             city   106.885025   2.4947  -4.5451\n",
       "889    Topic4   104.290154            inter   104.513176   2.4947  -4.5676\n",
       "232    Topic4   103.702515         transfer   103.928703   2.4947  -4.5732\n",
       "1278   Topic4    97.478027            level    97.712799   2.4945  -4.6351\n",
       "224    Topic4   104.445763           salary   104.697380   2.4945  -4.5661\n",
       "219    Topic4    90.537544     remuneration    90.765266   2.4944  -4.7090\n",
       "1019   Topic4    77.088615          request    77.317574   2.4939  -4.8698\n",
       "134    Topic4    68.829269       researcher    69.045044   2.4937  -4.9831\n",
       "1590   Topic4    59.325356    reimbursement    59.536667   2.4933  -5.1317\n",
       "733    Topic4    56.694443          account    56.916889   2.4930  -5.1771\n",
       "2441   Topic4    59.391159       memorandum    59.713345   2.4915  -5.1306\n",
       "147    Topic4  1328.248657            state  2492.391357   1.8675  -2.0231\n",
       "174    Topic4   206.197800        authority   390.981293   1.8570  -3.8859\n",
       "268    Topic4   113.884392            event   242.104874   1.7427  -4.4796\n",
       "806    Topic4   122.727379         teaching   473.190552   1.1473  -4.4048\n",
       "121    Topic4    91.909966        provision   399.172821   1.0283  -4.6939\n",
       "169    Topic5   610.937439            annex   611.118469   2.8156  -2.4807\n",
       "475    Topic5   573.237061            board   573.419495   2.8156  -2.5444\n",
       "128    Topic5   272.031616   recommendation   272.212830   2.8152  -3.2898\n",
       "828    Topic5   251.678833            child   251.857056   2.8152  -3.3676\n",
       "777    Topic5   232.002197           living   232.175354   2.8152  -3.4490\n",
       "2372   Topic5   240.977509           fields   241.162628   2.8151  -3.4110\n",
       "510    Topic5   175.341675         decision   175.524338   2.8149  -3.7290\n",
       "735    Topic5   150.038956   administration   150.217712   2.8147  -3.8848\n",
       "2404   Topic5   145.345291          illness   145.527115   2.8147  -3.9166\n",
       "1742   Topic5   145.607620          servant   145.799225   2.8146  -3.9148\n",
       "815    Topic5   124.054176          faculty   124.219818   2.8146  -4.0750\n",
       "107    Topic5   134.569656        paragraph   134.758163   2.8145  -3.9936\n",
       "113    Topic5   125.725494             post   125.902260   2.8145  -4.0616\n",
       "944    Topic5   108.153374         disposal   108.334137   2.8142  -4.2122\n",
       "1334   Topic5   105.120224   transportation   105.299225   2.8142  -4.2406\n",
       "2293   Topic5    84.256622         accident    84.433861   2.8138  -4.4619\n",
       "1230   Topic5    72.217010           policy    72.388916   2.8135  -4.6161\n",
       "1031   Topic5    65.198708             rate    65.369545   2.8133  -4.7183\n",
       "1719   Topic5    67.160446             week    67.343033   2.8132  -4.6886\n",
       "950    Topic5    64.756088          receipt    64.932190   2.8132  -4.7251\n",
       "1201   Topic5    65.663979    authorisation    65.847435   2.8131  -4.7112\n",
       "753    Topic5    59.438412         director    59.616020   2.8129  -4.8108\n",
       "998    Topic5    60.353970             hand    60.534435   2.8129  -4.7955\n",
       "1058   Topic5    53.145206           letter    53.328133   2.8125  -4.9227\n",
       "2704   Topic5    63.387089            death    63.621529   2.8122  -4.7465\n",
       "201    Topic5    45.672806           length    45.843678   2.8122  -5.0742\n",
       "1572   Topic5    42.464108        guarantee    42.628578   2.8120  -5.1471\n",
       "804    Topic5    43.220028      supervision    43.394459   2.8119  -5.1294\n",
       "2717   Topic5    62.115677           ground    62.366997   2.8119  -4.7667\n",
       "2395   Topic5    49.112347         hospital    49.321178   2.8117  -5.0016\n",
       "2282   Topic5    65.431488              pay    65.735016   2.8113  -4.7147\n",
       "2709   Topic5    82.615005       disability    83.243996   2.8083  -4.4815\n",
       "2549   Topic5   201.511612          tuition   206.576904   2.7911  -3.5899\n",
       "2766   Topic5   148.466904           spouse   158.198730   2.7524  -3.8954\n",
       "3081   Topic5   136.197784     compensation   150.819244   2.7139  -3.9816\n",
       "109    Topic5   320.859344           period   773.947754   1.9354  -3.1247\n",
       "2755   Topic5    96.495834     repatriation   130.792847   2.5118  -4.3262\n",
       "2731   Topic5    99.972733            leave   162.665680   2.3291  -4.2908\n",
       "1183   Topic5    77.908493     architecture   129.288132   2.3094  -4.5402\n",
       "103    Topic5    99.449387           number   351.684998   1.5528  -4.2961, token_table=      Topic  Freq     Term            \n",
       "term                                  \n",
       "471   3      0.998021          academy\n",
       "2293  5      0.994862         accident\n",
       "1699  4      0.997180    accommodation\n",
       "733   4      1.001460          account\n",
       "236   3      0.996612     acquaintance\n",
       "735   5      0.998551   administration\n",
       "239   1      1.000356          affairs\n",
       "241   2      0.997700              aim\n",
       "1411  4      0.997275        allowance\n",
       "169   5      0.999806            annex\n",
       "812   2      0.998690      appointment\n",
       "1183  3      0.394468     architecture\n",
       "1183  5      0.603304     architecture\n",
       "505   2      0.999492          archive\n",
       "171   1      0.230363           artist\n",
       "171   3      0.768738           artist\n",
       "247   1      0.998334      association\n",
       "1201  5      1.002317    authorisation\n",
       "174   1      0.053711        authority\n",
       "174   2      0.416900        authority\n",
       "174   4      0.526879        authority\n",
       "9     3      0.927438            basis\n",
       "9     4      0.071146            basis\n",
       "475   5      0.999268            board\n",
       "13    1      0.704098             book\n",
       "13    2      0.125248             book\n",
       "13    3      0.170383             book\n",
       "252   2      1.000500           centre\n",
       "390   2      1.000040      certificate\n",
       "22    1      0.998859          channel\n",
       "828   5      1.000568            child\n",
       "255   1      0.999199          citizen\n",
       "25    4      1.001076             city\n",
       "30    2      0.235771     co-operation\n",
       "30    3      0.764013     co-operation\n",
       "32    2      1.000267       collection\n",
       "33    1      0.431661       commission\n",
       "33    2      0.567446       commission\n",
       "3081  4      0.092826     compensation\n",
       "3081  5      0.901742     compensation\n",
       "906   4      1.000491       completion\n",
       "37    3      1.000254          contact\n",
       "182   2      0.998760       convention\n",
       "657   1      0.999933      cooperation\n",
       "750   4      0.999832             cost\n",
       "478   2      0.999408          council\n",
       "38    1      0.276237           course\n",
       "38    2      0.695584           course\n",
       "38    4      0.028289           course\n",
       "631   4      0.996734        curricula\n",
       "264   1      0.889880              day\n",
       "264   2      0.110064              day\n",
       "2704  5      0.990231            death\n",
       "40    1      1.000518         december\n",
       "510   5      0.997013         decision\n",
       "46    1      0.056312      development\n",
       "46    2      0.091058      development\n",
       "46    3      0.800351      development\n",
       "46    4      0.050321      development\n",
       "46    5      0.001198      development\n",
       "753   5      0.989667         director\n",
       "2709  5      0.997069       disability\n",
       "944   5      0.996916         disposal\n",
       "754   4      0.995086         document\n",
       "186   4      0.996927         duration\n",
       "53    1      0.128646        education\n",
       "53    2      0.214153        education\n",
       "53    3      0.656325        education\n",
       "53    4      0.000770        education\n",
       "53    5      0.000770        education\n",
       "57    2      0.666061    establishment\n",
       "57    3      0.333030    establishment\n",
       "268   1      0.380001            event\n",
       "268   3      0.148696            event\n",
       "268   4      0.470870            event\n",
       "270   3      0.998732          expense\n",
       "271   2      0.999384           expert\n",
       "815   5      0.998230          faculty\n",
       "273   2      1.000287          federal\n",
       "857   4      0.998957              fee\n",
       "1708  3      0.999230         festival\n",
       "59    2      0.087426            field\n",
       "59    3      0.912624            field\n",
       "2372  5      0.999326           fields\n",
       "275   1      1.000332          foreign\n",
       "519   3      0.997814       friendship\n",
       "405   2      1.000337            grant\n",
       "2717  5      0.994116           ground\n",
       "1572  5      0.985255        guarantee\n",
       "998   5      0.991171             hand\n",
       "280   3      1.001138           health\n",
       "66    1      0.998079          history\n",
       "2395  5      0.993488         hospital\n",
       "1149  4      0.999593             host\n",
       "834   3      0.998077            house\n",
       "522   2      0.999129              iii\n",
       "2404  5      0.996378          illness\n",
       "70    1      0.508266   implementation\n",
       "70    2      0.129038   implementation\n",
       "70    3      0.362023   implementation\n",
       "70    5      0.000717   implementation\n",
       "767   4      1.000994       importance\n",
       "283   3      0.999951      information\n",
       "284   1      0.999033       instrument\n",
       "889   4      0.995090            inter\n",
       "74    3      0.924880         interest\n",
       "74    4      0.076051         interest\n",
       "76    1      1.000192               iv\n",
       "526   2      0.998442               ix\n",
       "198   1      1.000287            joint\n",
       "285   3      0.998671       journalist\n",
       "199   1      0.998963             june\n",
       "78    4      1.000764       laboratory\n",
       "361   1      0.388919              law\n",
       "361   2      0.610576              law\n",
       "418   1      0.999262         learning\n",
       "2731  4      0.381150            leave\n",
       "2731  5      0.614758            leave\n",
       "79    1      0.232570          lecture\n",
       "79    3      0.764540          lecture\n",
       "200   2      1.000202      legislation\n",
       "201   5      1.003410           length\n",
       "1058  5      0.993847           letter\n",
       "1278  4      0.992705            level\n",
       "81    1      0.602876          library\n",
       "81    2      0.242780          library\n",
       "81    3      0.153163          library\n",
       "85    1      0.079901       literature\n",
       "85    2      0.030982       literature\n",
       "85    3      0.888691       literature\n",
       "777   5      0.999245           living\n",
       "88    1      0.998595           manner\n",
       "486   1      0.718574         material\n",
       "486   2      0.281559         material\n",
       "610   3      0.996395           matter\n",
       "2440  3      0.997254         medicine\n",
       "93    2      0.999842           member\n",
       "2441  4      0.988054       memorandum\n",
       "95    1      1.000277         minister\n",
       "780   4      1.000266          mission\n",
       "531   3      0.998993           museum\n",
       "613   3      0.998698            music\n",
       "97    1      0.519120         national\n",
       "97    2      0.480342         national\n",
       "1228  3      0.997988              new\n",
       "368   1      0.999911           notice\n",
       "369   2      0.999375     notification\n",
       "465   1      0.997986         november\n",
       "103   2      0.716550           number\n",
       "103   5      0.281502           number\n",
       "660   3      0.997639        objective\n",
       "105   1      0.998637            order\n",
       "106   2      0.892219     organisation\n",
       "106   3      0.107417     organisation\n",
       "297   3      1.000074     organization\n",
       "107   5      1.001795        paragraph\n",
       "974   1      0.998986    participation\n",
       "2282  5      0.988819              pay\n",
       "787   4      0.996083          payment\n",
       "108   3      0.999517           people\n",
       "109   1      0.103366           period\n",
       "109   2      0.162802           period\n",
       "109   3      0.316559           period\n",
       "109   4      0.002584           period\n",
       "109   5      0.414757           period\n",
       "374   2      1.000067        personnel\n",
       "212   1      0.999939            place\n",
       "213   1      1.000596  plenipotentiary\n",
       "1230  5      0.994627           policy\n",
       "113   5      1.000776             post\n",
       "305   1      0.999560        president\n",
       "306   3      0.999747            press\n",
       "117   1      1.000121        professor\n",
       "216   1      0.809497        programme\n",
       "216   3      0.189595        programme\n",
       "120   4      0.998730         protocol\n",
       "121   1      0.082671        provision\n",
       "121   2      0.683914        provision\n",
       "121   4      0.230477        provision\n",
       "121   5      0.002505        provision\n",
       "123   1      0.323429      publication\n",
       "123   3      0.676364      publication\n",
       "126   1      0.184021            radio\n",
       "126   2      0.109216            radio\n",
       "126   3      0.704666            radio\n",
       "1031  5      0.994347             rate\n",
       "310   1      0.999549     ratification\n",
       "2163  4      1.002057           reason\n",
       "950   5      1.001044          receipt\n",
       "493   3      1.001451      recognition\n",
       "128   5      0.999218   recommendation\n",
       "218   2      1.000278           regard\n",
       "1590  4      0.990986    reimbursement\n",
       "132   1      0.443816         relation\n",
       "132   3      0.554770         relation\n",
       "219   4      1.002586     remuneration\n",
       "2755  4      0.259953     repatriation\n",
       "2755  5      0.733985     repatriation\n",
       "220   1      0.864102   representative\n",
       "220   3      0.135997   representative\n",
       "1696  3      1.000736        republics\n",
       "1019  4      0.995893          request\n",
       "221   1      0.111238         research\n",
       "221   2      0.399926         research\n",
       "221   3      0.488651         research\n",
       "221   5      0.000662         research\n",
       "134   4      0.999348       researcher\n",
       "224   4      0.993339           salary\n",
       "139   1      0.998414      scholarship\n",
       "141   3      0.999379          science\n",
       "468   3      0.999202         sciences\n",
       "225   1      0.999882             seal\n",
       "692   2      0.998255        secretary\n",
       "226   4      0.997542         security\n",
       "1742  5      1.001377          servant\n",
       "595   2      0.999131          service\n",
       "1697  3      0.999777        socialist\n",
       "496   3      1.000351            sport\n",
       "2766  4      0.056890           spouse\n",
       "2766  5      0.935532           spouse\n",
       "800   4      1.000340            staff\n",
       "147   1      0.467021            state\n",
       "147   4      0.532822            state\n",
       "804   5      0.990910      supervision\n",
       "548   2      0.999357          support\n",
       "152   2      0.805098          teacher\n",
       "152   3      0.195059          teacher\n",
       "806   2      0.739660         teaching\n",
       "806   4      0.259938         teaching\n",
       "1738  3      0.998197       technology\n",
       "1102  3      0.999189       television\n",
       "325   2      1.000129             term\n",
       "230   2      1.000247        territory\n",
       "732   3      0.996666              tie\n",
       "596   2      0.997901             time\n",
       "597   3      0.998705          tourist\n",
       "232   4      1.000686         transfer\n",
       "327   3      0.996873      translation\n",
       "810   4      0.995776        transport\n",
       "1334  5      0.997158   transportation\n",
       "155   4      0.998937           travel\n",
       "2549  3      0.009682          tuition\n",
       "2549  4      0.014522          tuition\n",
       "2549  5      0.977844          tuition\n",
       "157   1      1.000124    understanding\n",
       "159   1      0.650882       university\n",
       "159   2      0.348806       university\n",
       "160   4      0.999855              use\n",
       "331   2      0.998375               vi\n",
       "233   1      0.757563             view\n",
       "233   2      0.242561             view\n",
       "556   2      0.999050             viii\n",
       "234   3      0.999413            visit\n",
       "1719  5      0.994906             week\n",
       "235   1      0.998961          whereof\n",
       "382   1      0.998605          witness\n",
       "163   1      0.053193             work\n",
       "163   3      0.908599             work\n",
       "163   4      0.037379             work\n",
       "334   2      0.107069           worker\n",
       "334   3      0.893359           worker\n",
       "1065  1      0.999780          writing\n",
       "561   2      1.000733               xi\n",
       "562   2      1.000679              xii\n",
       "563   2      0.999456             xiii\n",
       "564   2      1.000755              xiv\n",
       "566   2      0.998360               xv, R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[5, 4, 2, 1, 3])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pyLDAvis, pyLDAvis.gensim, pyLDAvis.sklearn\n",
    "import gensim\n",
    "pyLDAvis.enable_notebook()\n",
    "def display_pyLDAvis(state):\n",
    "\n",
    "    if isinstance(state.data.topic_model, textacy.tm.topic_model.TopicModel):\n",
    "        topic_model = state.data.topic_model.model\n",
    "    elif isinstance(state.data.topic_model, gensim.models.wrappers.LdaMallet):\n",
    "        topic_model = topic_model_utility.malletmodel2ldamodel(state.data.topic_model)\n",
    "    else:\n",
    "        topic_model = state.data.topic_model\n",
    "\n",
    "    if 'sklearn' in str(type(topic_model)):\n",
    "        p = pyLDAvis.sklearn.prepare(topic_model, state.data.bow_corpus, state.data.id2term)\n",
    "    else:\n",
    "        p = pyLDAvis.gensim.prepare(topic_model, state.data.bow_corpus, state.data.id2term)\n",
    "        \n",
    "    display(p)\n",
    "    \n",
    "display_pyLDAvis(current_state())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color: green;'>VISUALIZE</span> Display Topic's Word Distribution as a Chart<span style='color: red; float: right'>TRY IT</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": [
     3
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8245bcc26ea442249956710c374d6446",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=\"<span class='wc01'></span>\", placeholder=''), HBox(children=(Button(description='<<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display topic's word distribution\n",
    "import numpy as np\n",
    "\n",
    "def plot_topic_word_distribution(tokens, **args):\n",
    "\n",
    "    source = bokeh.models.ColumnDataSource(tokens)\n",
    "\n",
    "    p = bokeh.plotting.figure(toolbar_location=\"right\", **args)\n",
    "\n",
    "    cr = p.circle(x='xs', y='ys', source=source)\n",
    "\n",
    "    label_style = dict(level='overlay', text_font_size='8pt', angle=np.pi/6.0)\n",
    "\n",
    "    text_aligns = ['left', 'right']\n",
    "    for i in [0, 1]:\n",
    "        label_source = bokeh.models.ColumnDataSource(tokens.iloc[i::2])\n",
    "        labels = bokeh.models.LabelSet(x='xs', y='ys', text_align=text_aligns[i], text='token', text_baseline='middle',\n",
    "                          y_offset=5*(1 if i == 0 else -1),\n",
    "                          x_offset=5*(1 if i == 0 else -1),\n",
    "                          source=label_source, **label_style)\n",
    "        p.add_layout(labels)\n",
    "\n",
    "    p.xaxis[0].axis_label = 'Token #'\n",
    "    p.yaxis[0].axis_label = 'Probability%'\n",
    "    p.ygrid.grid_line_color = None\n",
    "    p.xgrid.grid_line_color = None\n",
    "    p.axis.axis_line_color = None\n",
    "    p.axis.major_tick_line_color = None\n",
    "    p.axis.major_label_text_font_size = \"6pt\"\n",
    "    p.axis.major_label_standoff = 0\n",
    "    return p\n",
    "\n",
    "def display_topic_tokens(state, topic_id=0, n_words=100, output_format='Chart', gui=None):\n",
    "    \n",
    "    def tick(n=None):\n",
    "        gui.progress.value = (gui.progress.value + 1) if n is None else n\n",
    "        \n",
    "    if gui.n_topics != state.num_topics:\n",
    "        gui.n_topics = state.num_topics\n",
    "        gui.topic_id.value = 0\n",
    "        gui.topic_id.max=state.num_topics - 1\n",
    "        \n",
    "    tick(1)\n",
    "    \n",
    "    tokens = topic_model_utility.get_topic_tokens(state.processed.topic_token_weights, topic_id=topic_id, n_tokens=n_words).\\\n",
    "        copy()\\\n",
    "        .drop('topic_id', axis=1)\\\n",
    "        .assign(weight=lambda x: 100.0 * x.weight)\\\n",
    "        .sort_values('weight', axis=0, ascending=False)\\\n",
    "        .reset_index()\\\n",
    "        .head(n_words)\n",
    "    \n",
    "    if output_format == 'Chart':\n",
    "        tick()\n",
    "        tokens = tokens.assign(xs=tokens.index, ys=tokens.weight)\n",
    "        p = plot_topic_word_distribution(tokens, plot_width=1200, plot_height=500, title='', tools='box_zoom,wheel_zoom,pan,reset')\n",
    "        bokeh.plotting.show(p)\n",
    "        tick()\n",
    "    else:\n",
    "        display(tokens)\n",
    "        \n",
    "    tick(0)\n",
    "    \n",
    "def display_topic_distribution_gui(state):\n",
    "    \n",
    "    text_id = 'wc01'\n",
    "    output_options = ['Chart', 'Table']\n",
    "    \n",
    "    gui = widgets_utility.WidgetUtility(\n",
    "        n_topics=state.num_topics,\n",
    "        text_id=text_id,\n",
    "        text=widgets_config.text(text_id),\n",
    "        topic_id=widgets.IntSlider(description='Topic ID', min=0, max=state.num_topics - 1, step=1, value=0),\n",
    "        n_words=widgets.IntSlider(description='#Words', min=5, max=500, step=1, value=75),\n",
    "        output_format=widgets.Dropdown(description='Format', options=output_options, value=output_options[0], layout=widgets.Layout(width=\"200px\")),\n",
    "        progress=widgets.IntProgress(min=0, max=4, step=1, value=0, layout=widgets.Layout(width=\"95%\"))\n",
    "    )\n",
    "\n",
    "    gui.prev_topic_id = gui.create_prev_id_button('topic_id', state.num_topics)\n",
    "    gui.next_topic_id = gui.create_next_id_button('topic_id', state.num_topics)\n",
    "\n",
    "    iw = widgets.interactive(\n",
    "        display_topic_tokens,\n",
    "        state=widgets.fixed(state),\n",
    "        topic_id=gui.topic_id,\n",
    "        n_words=gui.n_words,\n",
    "        output_format=gui.output_format,\n",
    "        gui=widgets.fixed(gui)\n",
    "    )\n",
    "\n",
    "    display(widgets.VBox([\n",
    "        gui.text,\n",
    "        widgets.HBox([gui.prev_topic_id, gui.next_topic_id, gui.topic_id, gui.n_words, gui.output_format]),\n",
    "        gui.progress,\n",
    "        iw.children[-1]\n",
    "    ]))\n",
    "\n",
    "    iw.update()\n",
    "\n",
    "try:\n",
    "    display_topic_distribution_gui(current_state())\n",
    "except Exception as ex:\n",
    "    logger.error(ex)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color: green;'>VISUALIZE</span> Display Topic's Trend Over Time or Documents<span style='color: red; float: right'>RUN</span>\n",
    "- Displays topic's share over documents.\n",
    "\n",
    "- BUGG? Values > 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69190c22f8814649a17468708de513fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=\"<span class='topic_share_plot'></span>\", placeholder=''), HBox(children=(Button(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot a topic's yearly weight over time in selected LDA topic model\n",
    "import math\n",
    "\n",
    "def plot_topic_trend(df, category_column, value_column, x_label=None, y_label=None, **figopts):\n",
    "    \n",
    "    xs = df[category_column].astype(np.str)\n",
    "    ys = df[value_column]\n",
    "    \n",
    "    figopts = utility.extend(dict(title='', toolbar_location=\"right\"), figopts)\n",
    "    \n",
    "    p = bokeh.plotting.figure(**figopts)\n",
    "\n",
    "    glyph = p.vbar(x=xs, top=ys, width=0.5, fill_color=\"#b3de69\")\n",
    "    \n",
    "    p.xaxis.major_label_orientation = math.pi/4\n",
    "    p.xgrid.grid_line_color = None\n",
    "    p.xaxis[0].axis_label = (x_label or category_column.title().replace('_', ' ')).title()\n",
    "    p.yaxis[0].axis_label = (y_label or value_column.title().replace('_', ' ')).title()\n",
    "    p.y_range.start = 0.0\n",
    "    p.x_range.range_padding = 0.01\n",
    "    \n",
    "    return p\n",
    "\n",
    "def display_topic_trend(\n",
    "    state,\n",
    "    topic_id,\n",
    "    year,\n",
    "    year_aggregate,\n",
    "    threshold=0.01,\n",
    "    output_format='Chart',\n",
    "    topic_changed=utility.noop\n",
    "):\n",
    "    figopts = dict(plot_width=1000, plot_height=700, title='', toolbar_location=\"right\")\n",
    "    \n",
    "    document_topic_weights = state.processed.document_topic_weights\n",
    "\n",
    "    topic_changed(topic_id)\n",
    "    \n",
    "    pivot_column = 'signed_year' if year is None else None\n",
    "    value_column = year_aggregate if year is None else 'weight'\n",
    "\n",
    "    df = document_topic_weights[(document_topic_weights.topic_id == topic_id)]\n",
    "    \n",
    "    if year is not None:\n",
    "        df = df[(df.signed_year == year)]\n",
    "        \n",
    "    df = df[(df.weight > threshold)].reset_index()\n",
    "    \n",
    "    if pivot_column is not None:\n",
    "        df = df.groupby([pivot_column, 'topic_id']).agg([np.mean, np.max])['weight'].reset_index()\n",
    "        df.columns = [pivot_column, 'topic_id', 'mean', 'max']\n",
    "        category_column = pivot_column\n",
    "        min_year = document_topic_weights.signed_year.min()\n",
    "        max_year = document_topic_weights.signed_year.max()\n",
    "        figopts['x_range'] = list(map(str, range(min_year, max_year+1))) # utility.complete_value_range(df[category_column].unique(), str)\n",
    "    else:\n",
    "        df['treaty'] = df.treaty_id + ' ' + df.party1 + ' ' + df.party2\n",
    "        category_column = 'treaty'\n",
    "        figopts['x_range'] = df['treaty'].unique()\n",
    "        \n",
    "    if output_format == 'Table':\n",
    "        display(df)\n",
    "    else:\n",
    "        p = plot_topic_trend(df, category_column, value_column, **figopts)\n",
    "        bokeh.plotting.show(p)\n",
    "\n",
    "def display_topic_trend_gui(state):\n",
    "    \n",
    "    year_options = [ ('all years', None) ] + [ (x,x) for x in range(state.processed.year_period[0], state.processed.year_period[1] + 1)]\n",
    "    \n",
    "    text_id = 'topic_share_plot'\n",
    "    \n",
    "    gui = widgets_utility.WidgetUtility(\n",
    "        n_topics=state.num_topics,\n",
    "        text_id=text_id,\n",
    "        text=widgets_config.text(text_id),\n",
    "        year=widgets.Dropdown(description='Year', options=year_options, value=None),\n",
    "        year_aggregate=widgets.Dropdown(description='Aggregate', options=['mean', 'max'], value='max'),\n",
    "        threshold=widgets.FloatSlider(description='Threshold', min=0.0, max=0.25, step=0.01, value=0.10, continuous_update=False),\n",
    "        topic_id=widgets.IntSlider(description='Topic ID', min=0, max=state.num_topics - 1, step=1, value=0, continuous_update=False),\n",
    "        output_format=widgets.Dropdown(description='Format', options=['Chart', 'Table'], value='Chart'),\n",
    "        progress=widgets.IntProgress(min=0, max=4, step=1, value=0, layout=widgets.Layout(width=\"50%\")),\n",
    "    )\n",
    "    \n",
    "    gui.prev_topic_id = gui.create_prev_id_button('topic_id', state.num_topics)\n",
    "    gui.next_topic_id = gui.create_next_id_button('topic_id', state.num_topics)\n",
    "    \n",
    "    def on_topic_changed(topic_id):\n",
    "        \n",
    "        if gui.n_topics != state.num_topics:\n",
    "            gui.n_topics = state.num_topics\n",
    "            gui.topic_id.value = 0\n",
    "            gui.topic_id.max = state.num_topics - 1\n",
    "            \n",
    "        tokens = topic_model_utility.get_topic_title(state.processed.topic_token_weights, topic_id, n_tokens=200)\n",
    "        gui.text.value = 'ID {}: {}'.format(topic_id, tokens)\n",
    "        \n",
    "    iw = widgets.interactive(\n",
    "        display_topic_trend,\n",
    "        state=widgets.fixed(state),\n",
    "        topic_id=gui.topic_id,\n",
    "        year=gui.year,\n",
    "        year_aggregate=gui.year_aggregate,\n",
    "        threshold=gui.threshold,\n",
    "        output_format=gui.output_format,\n",
    "        topic_changed=widgets.fixed(on_topic_changed)\n",
    "    )\n",
    "\n",
    "    display(widgets.VBox([\n",
    "        gui.text,\n",
    "        widgets.HBox([gui.prev_topic_id, gui.next_topic_id, gui.year, gui.year_aggregate, gui.output_format]),\n",
    "        widgets.HBox([gui.topic_id, gui.threshold, gui.progress]),\n",
    "        iw.children[-1]\n",
    "    ]))\n",
    "    \n",
    "    iw.update()\n",
    "\n",
    "try:\n",
    "    display_topic_trend_gui(current_state())\n",
    "except Exception as ex:\n",
    "    logger.error(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color: green;'>VISUALIZE</span> Display Topic to Document Network<span style='color: red; float: right'>TRY IT</span>\n",
    "The green nodes are documents, and blue nodes are topics. The edges (lines) indicates the strength of a topic in the connected document. The width of the edge is proportinal to the strength of the connection. Note that only edges with a strength above the certain threshold are displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ab68039ba714ea583276c613565aae4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(VBox(children=(Dropdown(description='Layout', index=2, layout=Layout(width='250p…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize year-to-topic network by means of topic-document-weights\n",
    "from common.plot_utility import layout_algorithms, PlotNetworkUtility\n",
    "from common.network_utility import NetworkUtility, DISTANCE_METRICS, NetworkMetricHelper\n",
    "\n",
    "def plot_document_topic_network(network, layout, scale=1.0, titles=None):\n",
    "    tools = \"pan,wheel_zoom,box_zoom,reset,hover,previewsave\"\n",
    "    year_nodes, topic_nodes = NetworkUtility.get_bipartite_node_set(network, bipartite=0)  \n",
    "    \n",
    "    year_source = NetworkUtility.get_node_subset_source(network, layout, year_nodes)\n",
    "    topic_source = NetworkUtility.get_node_subset_source(network, layout, topic_nodes)\n",
    "    lines_source = NetworkUtility.get_edges_source(network, layout, scale=6.0, normalize=False)\n",
    "    \n",
    "    edges_alphas = NetworkMetricHelper.compute_alpha_vector(lines_source.data['weights'])\n",
    "    \n",
    "    lines_source.add(edges_alphas, 'alphas')\n",
    "    \n",
    "    p = bokeh.plotting.figure(plot_width=1000, plot_height=600, x_axis_type=None, y_axis_type=None, tools=tools)\n",
    "    \n",
    "    r_lines = p.multi_line(\n",
    "        'xs', 'ys', line_width='weights', alpha='alphas', color='black', source=lines_source\n",
    "    )\n",
    "    r_years = p.circle(\n",
    "        'x','y', size=40, source=year_source, color='lightgreen', level='overlay', line_width=1,alpha=1.0\n",
    "    )\n",
    "    \n",
    "    r_topics = p.circle('x','y', size=25, source=topic_source, color='skyblue', level='overlay', alpha=1.00)\n",
    "    \n",
    "    p.add_tools(bokeh.models.HoverTool(renderers=[r_topics], tooltips=None, callback=widgets_utility.wf.\\\n",
    "        glyph_hover_callback(topic_source, 'node_id', text_ids=titles.index, text=titles, element_id='nx_id1'))\n",
    "    )\n",
    "\n",
    "    text_opts = dict(x='x', y='y', text='name', level='overlay', x_offset=0, y_offset=0, text_font_size='8pt')\n",
    "    \n",
    "    p.add_layout(\n",
    "        bokeh.models.LabelSet(\n",
    "            source=year_source, text_color='black', text_align='center', text_baseline='middle', **text_opts\n",
    "        )\n",
    "    )\n",
    "    p.add_layout(\n",
    "        bokeh.models.LabelSet(\n",
    "            source=topic_source, text_color='black', text_align='center', text_baseline='middle', **text_opts\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return p\n",
    "        \n",
    "def display_document_topic_network(layout_algorithm, state, threshold=0.10, parties=None, period=None, ignores=None, scale=1.0, output_format='network', tick=utility.noop):\n",
    "\n",
    "    tick(1)\n",
    "    \n",
    "    topic_token_weights = state.processed.topic_token_weights\n",
    "    document_topic_weights = state.processed.document_topic_weights\n",
    "    \n",
    "    titles = topic_model_utility.get_topic_titles(topic_token_weights)\n",
    "\n",
    "    df = document_topic_weights[document_topic_weights.weight > threshold].reset_index()\n",
    "\n",
    "    if len(parties or []) > 0:\n",
    "        df = df[df.party1.isin(parties) | df.party2.isin(parties)]\n",
    "\n",
    "    if len(period or []) == 2:\n",
    "        df = df[(df.signed_year>=period[0]) & (df.signed_year<=period[1])]\n",
    "        \n",
    "    if len(ignores or []) > 0:\n",
    "        df = df[~df.topic_id.isin(ignores)]\n",
    "\n",
    "    df['weight'] = utility.clamp_values(list(df.weight), (0.1, 2.0))\n",
    "\n",
    "    if len(df) == 0:\n",
    "        print('No data')\n",
    "        return\n",
    "    \n",
    "    df['title'] = df.treaty_id + ' ' + df.party1 + ' ' + df.party2\n",
    "\n",
    "    network = NetworkUtility.create_bipartite_network(df, 'title', 'topic_id')\n",
    "    tick()\n",
    "\n",
    "    if output_format == 'network':\n",
    "        args = PlotNetworkUtility.layout_args(layout_algorithm, network, scale)\n",
    "        layout = (layout_algorithms[layout_algorithm])(network, **args)\n",
    "        tick()\n",
    "        p = plot_document_topic_network(network, layout, scale=scale, titles=titles)\n",
    "        bokeh.plotting.show(p)\n",
    "\n",
    "    elif output_format == 'table':\n",
    "        display(df)\n",
    "\n",
    "    tick(0)\n",
    "        \n",
    "def document_topic_network_gui(wti_index, state):\n",
    "    \n",
    "    lw = lambda w: widgets.Layout(width=w)\n",
    "    \n",
    "    text_id = 'nx_id1'\n",
    "    layout_options = [ 'Circular', 'Kamada-Kawai', 'Fruchterman-Reingold']\n",
    "    party_preset_options = wti_index.get_party_preset_options()\n",
    "    parties_options = [ x for x in wti_index.get_countries_list() if x not in ['ALL', 'ALL OTHER'] ]\n",
    "    year_min, year_max = state.processed.year_period\n",
    "    \n",
    "    n_topics = state.num_topics\n",
    "    \n",
    "    gui = types.SimpleNamespace(\n",
    "        text=widgets_config.text(text_id),\n",
    "        period=widgets.IntRangeSlider(description='Time', min=year_min, max=year_min+5, step=1, value=(year_min, year_max), continues_update=False),\n",
    "        scale=widgets.FloatSlider(description='Scale', min=0.0, max=1.0, step=0.01, value=0.1, continues_update=False),\n",
    "        threshold=widgets.FloatSlider(description='Threshold', min=0.0, max=1.0, step=0.01, value=0.50, continues_update=False),\n",
    "        output_format=widgets_utility.dropdown('Output', { 'Network': 'network', 'Table': 'table' }, 'network', layout=lw('200px')),\n",
    "        layout=widgets_utility.dropdown('Layout', layout_options, 'Fruchterman-Reingold', layout=lw('250px')),\n",
    "        parties=widgets.SelectMultiple(description='Parties', options=parties_options, value=['FRANCE'], rows=7, layout=lw('180px')),\n",
    "        party_preset=widgets_config.dropdown('Presets', party_preset_options, None, layout=lw('180px')),\n",
    "        progress=widgets.IntProgress(min=0, max=4, step=1, value=0, layout=widgets.Layout(width=\"99%\")),\n",
    "        ignores=widgets.SelectMultiple(description='Ignore', options=[('', None)] + [ ('Topic #'+str(i), i) for i in range(0, n_topics) ], value=[], rows=8, layout=lw('180px')),\n",
    "    )\n",
    "    \n",
    "    def tick(x=None):\n",
    "        gui.progress.value = gui.progress.value + 1 if x is None else x\n",
    "        \n",
    "    def on_party_preset_change(change):  # pylint: disable=W0613\n",
    "        if gui.party_preset.value is None:\n",
    "            return\n",
    "        gui.parties.value = gui.parties.options if 'ALL' in gui.party_preset.value else gui.party_preset.value\n",
    "            \n",
    "    gui.party_preset.observe(on_party_preset_change, names='value')\n",
    "    \n",
    "    iw = widgets.interactive(\n",
    "        display_document_topic_network,\n",
    "        layout_algorithm=gui.layout,\n",
    "        state=widgets.fixed(state),\n",
    "        threshold=gui.threshold,\n",
    "        parties=gui.parties,\n",
    "        period=gui.period,\n",
    "        ignores=gui.ignores,\n",
    "        scale=gui.scale,\n",
    "        output_format=gui.output_format,\n",
    "        tick=widgets.fixed(tick)\n",
    "    )\n",
    "\n",
    "    display(widgets.VBox([\n",
    "        widgets.HBox([\n",
    "            widgets.VBox([gui.layout, gui.threshold, gui.scale, gui.period]), \n",
    "            widgets.VBox([gui.parties, gui.party_preset]), \n",
    "            widgets.VBox([gui.ignores]), \n",
    "            widgets.VBox([gui.output_format, gui.progress]),\n",
    "        ]),\n",
    "        iw.children[-1],\n",
    "        gui.text,\n",
    "    ]))\n",
    "    iw.update()\n",
    "\n",
    "try:\n",
    "    document_topic_network_gui(WTI_INDEX, current_state())\n",
    "except Exception as ex:\n",
    "    logger.error(ex)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color: green;'>VISUALIZE</span> Topic Trends Overview<span style='color: red; float: right'>TRY IT</span>\n",
    "\n",
    "- The topic shares  displayed as a scattered heatmap plot using gradient color based on topic's weight in document.\n",
    "- [Stanford’s Termite software](http://vis.stanford.edu/papers/termite) uses a similar visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e0b9c634c9049d7813a6bc234abfd8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Year', layout=Layout(width='160px'), options=(('all years'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot_topic_relevance_by_year\n",
    "import bokeh.transform\n",
    "\n",
    "def get_topic_weight_by_year_or_document(document_topic_weights, key='mean', year=None):\n",
    "    pivot_column = 'year' if year is None else 'document_id'\n",
    "    #if df[(df.year == year)]\n",
    "    df = self.get_document_topic_weights(year) \\\n",
    "        .groupby([pivot_column,'topic_id']) \\\n",
    "        .agg(config.AGGREGATES[key])[['weight']].reset_index()\n",
    "    return df, pivot_column\n",
    "    \n",
    "def setup_glyph_coloring(df):\n",
    "    max_weight = df.weight.max()\n",
    "    #colors = list(reversed(bokeh.palettes.Greens[9]))\n",
    "    colors = ['#ffffff', '#f7fcf5', '#e5f5e0', '#c7e9c0', '#a1d99b', '#74c476', '#41ab5d', '#238b45', '#006d2c', '#00441b']\n",
    "    mapper = bokeh.models.LinearColorMapper(palette=colors, low=0.0, high=1.0) # low=df.weight.min(), high=max_weight)\n",
    "    color_transform = bokeh.transform.transform('weight', mapper)\n",
    "    color_bar = bokeh.models.ColorBar(color_mapper=mapper, location=(0, 0),\n",
    "                         ticker=bokeh.models.BasicTicker(desired_num_ticks=len(colors)),\n",
    "                         formatter=bokeh.models.PrintfTickFormatter(format=\" %5.2f\"))\n",
    "    return color_transform, color_bar\n",
    "\n",
    "def compute_int_range_categories(values):\n",
    "    categories = values.unique()\n",
    "    if all(map(utility.isint, categories)):\n",
    "        categories = sorted(list(map(int, categories)))\n",
    "        return list(map(str, categories))\n",
    "    else:\n",
    "        return sorted(list(categories))\n",
    "\n",
    "HEATMAP_FIGOPTS = dict(title=\"Topic heatmap\", toolbar_location=\"right\",  x_axis_location=\"above\", plot_width=1000)\n",
    "\n",
    "def plot_topic_relevance_by_year(df, xs, ys, flip_axis, titles, text_id, **figopts):\n",
    "\n",
    "    line_height = 7\n",
    "    if flip_axis is True:\n",
    "        xs, ys = ys, xs\n",
    "        line_height = 10\n",
    "\n",
    "    x_range = compute_int_range_categories(df[xs])\n",
    "    y_range = compute_int_range_categories(df[ys])\n",
    "    \n",
    "    color_transform, color_bar = setup_glyph_coloring(df)\n",
    "    \n",
    "    source = bokeh.models.ColumnDataSource(df)\n",
    "\n",
    "    if x_range is not None:\n",
    "        figopts['x_range'] = x_range\n",
    "\n",
    "    if y_range is not None:\n",
    "        figopts['y_range'] = y_range\n",
    "        figopts['plot_height'] = max(len(y_range) * line_height, 500)\n",
    "    \n",
    "    p = bokeh.plotting.figure(**figopts)\n",
    "\n",
    "    args = dict(x=xs, y=ys, source=source, alpha=1.0, hover_color='red')\n",
    "    \n",
    "    cr = p.rect(width=1, height=1, line_color=None, fill_color=color_transform, **args)\n",
    "\n",
    "    p.x_range.range_padding = 0\n",
    "    p.ygrid.grid_line_color = None\n",
    "    p.xgrid.grid_line_color = None\n",
    "    p.axis.axis_line_color = None\n",
    "    p.axis.major_tick_line_color = None\n",
    "    p.axis.major_label_text_font_size = \"8pt\"\n",
    "    p.axis.major_label_standoff = 0\n",
    "    p.xaxis.major_label_orientation = 1.0\n",
    "    p.add_layout(color_bar, 'right')\n",
    "    \n",
    "    p.add_tools(bokeh.models.HoverTool(tooltips=None, callback=widgets_utility.WidgetUtility.glyph_hover_callback(\n",
    "        source, 'topic_id', titles.index, titles, text_id), renderers=[cr]))\n",
    "    \n",
    "    return p\n",
    "\n",
    "def display_doc_topic_heatmap(state, key='max', flip_axis=False, glyph='Circle', year=None, year_aggregate=None, output_format=None):\n",
    "    try:\n",
    "\n",
    "        titles = topic_model_utility.get_topic_titles(state.processed.topic_token_weights, n_tokens=100)\n",
    "        \n",
    "        df = state.processed.document_topic_weights.copy()\n",
    "\n",
    "        if year is not None:\n",
    "            df = df[(df.signed_year == year)]\n",
    "\n",
    "        if year is None:\n",
    "            \n",
    "            ''' Display aggregate value grouped by year  '''\n",
    "            df = df.groupby(['signed_year', 'topic_id']).agg([np.mean, np.max])['weight'].reset_index()\n",
    "            df.columns = ['signed_year', 'topic_id', 'mean', 'max']\n",
    "            df['weight'] = df[year_aggregate]\n",
    "            df['signed_year'] = df.signed_year.astype(str)\n",
    "            category_column = 'signed_year'\n",
    "            \n",
    "        else:\n",
    "            ''' Display individual treaties for selected year  '''\n",
    "            df['treaty'] = df.treaty_id + ' ' + df.party1 + ' ' + df.party2\n",
    "            df = df[['treaty', 'treaty_id', 'topic_id', 'weight']]\n",
    "            category_column = 'treaty'  \n",
    "        \n",
    "        df['document_id'] = df.index.astype(str)\n",
    "        df['topic_id'] = df.topic_id.astype(str)\n",
    "         \n",
    "        if output_format.lower() == 'heatmap':\n",
    "            \n",
    "            p = plot_topic_relevance_by_year(\n",
    "                df,\n",
    "                xs=category_column,\n",
    "                ys='topic_id',\n",
    "                flip_axis=flip_axis,\n",
    "                titles=titles,\n",
    "                text_id='topic_relevance',\n",
    "                **HEATMAP_FIGOPTS)\n",
    "\n",
    "            bokeh.plotting.show(p)\n",
    "            \n",
    "        else:\n",
    "            display(df)\n",
    "        \n",
    "    except Exception as ex:\n",
    "        raise\n",
    "        logger.error(ex)\n",
    "        \n",
    "def doc_topic_heatmap_gui(state):\n",
    "\n",
    "    lw = lambda w: widgets.Layout(width=w)\n",
    "    \n",
    "    text_id = 'topic_relevance'\n",
    "    \n",
    "    year_min, year_max = state.processed.year_period\n",
    "    year_options = [ ('all years', None) ] + [ (x,x) for x in range(year_min, year_max + 1)]\n",
    "    \n",
    "    gui = types.SimpleNamespace(\n",
    "        text_id=text_id,\n",
    "        text=widgets_config.text(text_id),\n",
    "        flip_axis=widgets.ToggleButton(value=True, description='Flip', icon='', layout=lw(\"80px\")),\n",
    "        year=widgets.Dropdown(description='Year', options=year_options, value=None, layout=lw(\"160px\")),\n",
    "        year_aggregate=widgets.Dropdown(description='Aggregate', options=['mean', 'max'], value='max', layout=lw(\"160px\")),\n",
    "        output_format=widgets.Dropdown(description='Output', options=['Heatmap', 'Table'], value='Heatmap', layout=lw(\"180px\"))\n",
    "    )\n",
    "    \n",
    "    iw = widgets.interactive(\n",
    "        display_doc_topic_heatmap,\n",
    "        state=widgets.fixed(state),\n",
    "        flip_axis=gui.flip_axis,\n",
    "        year=gui.year,\n",
    "        year_aggregate=gui.year_aggregate,\n",
    "        output_format=gui.output_format\n",
    "    )\n",
    "\n",
    "    display(widgets.VBox([\n",
    "        widgets.HBox([gui.year, gui.year_aggregate, gui.output_format, gui.flip_axis ]),\n",
    "        widgets.HBox([iw.children[-1]]), gui.text\n",
    "    ]))\n",
    "\n",
    "    iw.update()\n",
    "\n",
    "try:\n",
    "    doc_topic_heatmap_gui(current_state())\n",
    "except Exception as ex:\n",
    "    logger.error(ex)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86c0e1f7d7314d9892ff9e3d0a53ac18",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# TODO SOMETHING IS WRONG WITH THE WEIGHT!!!\n",
    "current_state().processed.document_topic_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color: green;'>VISUALIZE</span> Topic Cooccurrence<span style='color: red; float: right'>TRY IT</span>\n",
    "\n",
    "Computes weighted graph of topics co-occurring in the same document. Topics are defined as co-occurring if they both exists  in the same document both having weights above threshold. Weight are number of co-occurrences (binary yes or no). Node size reflects topic proportions over the entire corpus (normalized document) length, and are computed in accordance to how node sizes are computed in LDAvis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualize topic co-occurrence\n",
    "\n",
    "import common.plot_utility as plot_utility\n",
    "import common.network_utility as network_utility\n",
    "import bokeh.plotting # import figure, show, output_notebook, output_file\n",
    "\n",
    "bokeh.plotting.output_notebook()\n",
    "\n",
    "def get_topic_titles(topic_token_weights, topic_id=None, n_words=100):\n",
    "    df_temp = topic_token_weights if topic_id is None else topic_token_weights[(topic_token_weights.topic_id==topic_id)]\n",
    "    df = df_temp\\\n",
    "            .sort_values('weight', ascending=False)\\\n",
    "            .groupby('topic_id')\\\n",
    "            .apply(lambda x: ' '.join(x.token[:n_words].str.title()))\n",
    "    return df\n",
    "\n",
    "# FIXME: add doc token length to df_documents\n",
    "def get_topic_proportions(corpus_documents, document_topic_weights):\n",
    "    topic_proportion = topic_model.compute_topic_proportions(document_topic_weights, corpus_documents)\n",
    "    return topic_proportion\n",
    "    \n",
    "def display_topic_co_occurrence_network(\n",
    "    tm_data,\n",
    "    parties=None,\n",
    "    period=None,\n",
    "    ignores=None,\n",
    "    threshold=0.10,\n",
    "    layout='Fruchterman-Reingold',\n",
    "    scale=1.0,\n",
    "    output_format='table'\n",
    "):\n",
    "    try:\n",
    "        \n",
    "        model_data = tm_data.compiled_data\n",
    "        \n",
    "        titles = topic_model_utility.get_topic_titles(model_data.topic_token_weights)\n",
    "        df = model_data.document_topic_weights\n",
    "        df['document_id'] = df.index\n",
    "        \n",
    "        node_sizes = topic_model.compute_topic_proportions(df, model_data.documents)\n",
    "\n",
    "        if ignores is not None:\n",
    "            df = df[~df.topic_id.isin(ignores)]\n",
    "            \n",
    "        if len(parties or []) > 0:\n",
    "            df = df[df.party1.isin(parties) | df.party2.isin(parties)]\n",
    "            \n",
    "        if period is not None:\n",
    "            df = df[df.signed_year.between(period[0], period[1], inclusive=True)]\n",
    "            \n",
    "        df = df.loc[(df.weight >= threshold)]\n",
    "        df = pd.merge(df, df, how='inner', left_on='document_id', right_on='document_id')\n",
    "        df = df.loc[(df.topic_id_x < df.topic_id_y)]\n",
    "        df = df.groupby([df.topic_id_x, df.topic_id_y]).size().reset_index()\n",
    "        df.columns = ['source', 'target', 'weight']\n",
    "        \n",
    "        if len(df) == 0:\n",
    "            print('No data. Please change selections.')\n",
    "            return\n",
    "        \n",
    "        if output_format == 'table':\n",
    "            display(df)\n",
    "        else:\n",
    "            network = network_utility.NetworkUtility.create_network(df, source_field='source', target_field='target', weight='weight')\n",
    "            p = plot_utility.PlotNetworkUtility.plot_network(\n",
    "                network=network,\n",
    "                layout_algorithm=layout,\n",
    "                scale=scale,\n",
    "                threshold=0.0,\n",
    "                node_description=titles,\n",
    "                node_proportions=node_sizes,\n",
    "                weight_scale=10.0,\n",
    "                normalize_weights=True,\n",
    "                element_id='cooc_id',\n",
    "                figsize=(900,500)\n",
    "            )\n",
    "            bokeh.plotting.show(p)\n",
    "\n",
    "    except Exception as x:\n",
    "        raise\n",
    "        print(\"No data: please adjust filters\")\n",
    "\n",
    "def topic_coocurrence_network_gui(wti_index, tm_data):\n",
    "    \n",
    "    lw = lambda w: widgets.Layout(width=w)\n",
    "    n_topics = tm_data.tm_model.num_topics\n",
    "    \n",
    "    model = tm_data.tm_model\n",
    "    text_id = 'cooc_id'\n",
    "    layout_options = [ 'Circular', 'Kamada-Kawai', 'Fruchterman-Reingold']\n",
    "    party_preset_options = wti_index.get_party_preset_options()\n",
    "    parties_options = [ x for x in wti_index.get_countries_list() if x != 'ALL OTHER' ]\n",
    "    year_min, year_max = tm_data.compiled_data.year_period\n",
    "    \n",
    "    gui = types.SimpleNamespace(\n",
    "        n_topics=n_topics,\n",
    "        text=widgets_utility.wf.create_text_widget(text_id),\n",
    "        period=widgets.IntRangeSlider(description='Time', min=year_min, max=year_max, step=1, value=(year_min, year_max), continues_update=False),\n",
    "        scale=widgets.FloatSlider(description='Scale', min=0.0, max=1.0, step=0.01, value=0.1, continues_update=False),\n",
    "        threshold=widgets.FloatSlider(description='Threshold', min=0.0, max=1.0, step=0.01, value=0.20, continues_update=False),\n",
    "        output_format=widgets_utility.dropdown('Output', { 'Network': 'network', 'Table': 'table' }, 'network', layout=lw('200px')),\n",
    "        layout=widgets_utility.dropdown('Layout', layout_options, 'Fruchterman-Reingold', layout=lw('250px')),\n",
    "        parties=widgets.SelectMultiple(description='Parties', options=parties_options, value=[], rows=7, layout=lw('180px')),\n",
    "        party_preset=widgets_config.dropdown('Presets', party_preset_options, None, layout=lw('180px')),\n",
    "        progress=widgets.IntProgress(min=0, max=4, step=1, value=0, layout=widgets.Layout(width=\"99%\")),\n",
    "        ignores=widgets.SelectMultiple(description='Ignore', options=[('', None)] + [ ('Topic #'+str(i), i) for i in range(0, n_topics) ], value=[], rows=8, layout=lw('180px')),\n",
    "    )\n",
    "    def tick(x=None):\n",
    "        gui.progress.value = gui.progress.value + 1 if x is None else x\n",
    "        \n",
    "    def on_party_preset_change(change):  # pylint: disable=W0613\n",
    "        if gui.party_preset.value is None:\n",
    "            return\n",
    "        gui.parties.value = gui.parties.options if 'ALL' in gui.party_preset.value else gui.party_preset.value\n",
    "            \n",
    "    gui.party_preset.observe(on_party_preset_change, names='value')\n",
    "     \n",
    "    iw = widgets.interactive(\n",
    "        display_topic_co_occurrence_network,\n",
    "        tm_data=widgets.fixed(tm_data),\n",
    "        parties=gui.parties,\n",
    "        period=gui.period,\n",
    "        ignores=gui.ignores,\n",
    "        threshold=gui.threshold,\n",
    "        layout=gui.layout,\n",
    "        scale=gui.scale,\n",
    "        output_format=gui.output_format\n",
    "    )\n",
    "    display(widgets.VBox([\n",
    "        gui.text,\n",
    "        widgets.HBox([\n",
    "            widgets.VBox([gui.layout, gui.threshold, gui.scale, gui.period]), \n",
    "            widgets.VBox([gui.parties, gui.party_preset]), \n",
    "            widgets.VBox([gui.ignores]), \n",
    "            widgets.VBox([gui.output_format, gui.progress]),\n",
    "        ]),\n",
    "        iw.children[-1]\n",
    "    ]))\n",
    "    iw.update()\n",
    "    \n",
    "try:\n",
    "    tm_data = get_current_model()\n",
    "    topic_coocurrence_network_gui(WTI_INDEX, tm_data)\n",
    "except Exception as ex:\n",
    "    logger.error(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color: green'>EXPLORE </span> Topic Similarity <span style='float: right; color: red'>WORK IN PROGRESS</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style='color: green'>EXPLORE </span> Topic Similarity Network<span style='float: right; color: red'>WORK IN PROGRESS</span>\n",
    "This plot displays topic similarity based on **euclidean or cosine distances** between the **topic-to-word vectors**. Please note that the computations can take some time to exceute, especially for larger LDA models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualization\n",
    "import types\n",
    "\n",
    "# if 'zy_data' not in globals():\n",
    "zy_data = types.SimpleNamespace(\n",
    "    basename=None,\n",
    "    network=None,\n",
    "    X_n_space=None,\n",
    "    X_n_space_feature_names=None,\n",
    "    distance_matrix=None,\n",
    "    metric=None,\n",
    "    topic_proportions=None,\n",
    "    n_words = 0\n",
    ")\n",
    "\n",
    "def plot_clustering_dendogram(clustering):\n",
    "    plt.figure(figsize=(16,6))\n",
    "    # https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.cluster.hierarchy.dendrogram.html\n",
    "    R = dendrogram(clustering)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def VectorSpaceHelper_compute_distance_matrix(X_n_space, metric='euclidean'):\n",
    "    # https://se.mathworks.com/help/stats/pdist.html\n",
    "    metric = metric.lower()\n",
    "    if metric == 'kullback–leibler': metric = VectorSpaceHelper.kullback_leibler_divergence\n",
    "    if metric == 'scipy.stats.entropy': metric = scipy.stats.entropy\n",
    "    #print(metric)\n",
    "    X = X_n_space.toarray() if hasattr(X_n_space, 'toarray') else X_n_space\n",
    "    #X_n_space += 0.00001\n",
    "    distances = distance.pdist(X, metric=metric)\n",
    "    #print(distances)\n",
    "    distance_matrix = distance.squareform(distances)\n",
    "    #print(distance_matrix)    \n",
    "    return distance_matrix\n",
    "    \n",
    "def display_correlation_network(\n",
    "    layout_algorithm,\n",
    "    threshold=0.10,\n",
    "    scale=1.0,\n",
    "    metric='Euclidean',\n",
    "    n_words=200,\n",
    "    output_format='Network'\n",
    "):\n",
    "    global state, zy_data, zy\n",
    "\n",
    "    try:\n",
    "\n",
    "        zy.progress.value = 1\n",
    "        metric = DISTANCE_METRICS[metric]\n",
    "\n",
    "        node_description = state.get_topics_tokens_as_text()\n",
    "        node_proportions = state.get_topic_proportions()\n",
    "\n",
    "        zy.progress.value = 2\n",
    "        if zy_data.network is None or state.basename != zy_data.basename or zy_data.metric != metric or zy_data.n_words != n_words:\n",
    "\n",
    "            zy_data.basename = state.basename\n",
    "            zy_data.n_words = n_words\n",
    "            zy_data.X_n_space, zy_data.X_n_space_feature_names = state.compute_topic_terms_vector_space(n_words=n_words)\n",
    "            \n",
    "            #print(zy_data.X_n_space.shape)\n",
    "            #print(zy_data.X_n_space_feature_names)\n",
    "            zy.progress.value = 3\n",
    "            zy_data.distance_matrix = VectorSpaceHelper_compute_distance_matrix(zy_data.X_n_space, metric=metric)\n",
    "            zy_data.network = None\n",
    "\n",
    "        edges_data = VectorSpaceHelper.lower_triangle_iterator(zy_data.distance_matrix, threshold)\n",
    "\n",
    "        zy.progress.value = 4\n",
    "        if output_format == 'List':\n",
    "            df = pd.DataFrame(edges_data, columns=['x', 'y', 'weight'])\n",
    "            zy.progress.value = 5\n",
    "            display(HTML(df.to_html()))\n",
    "        else:\n",
    "            zy.progress.value = 5\n",
    "            if zy_data.network is None:\n",
    "                zy_data.network = NetworkUtility.create_network_from_xyw_list(edges_data) # zy_data.distance_matrix)\n",
    "            zy.progress.value = 6\n",
    "            p = PlotNetworkUtility.plot_network(\n",
    "                network=zy_data.network,\n",
    "                layout_algorithm=layout_algorithm,\n",
    "                scale=scale,\n",
    "                threshold=threshold,\n",
    "                node_description=node_description,\n",
    "                node_proportions=node_proportions,\n",
    "                element_id='nx_id3',\n",
    "                figsize=(1000,600)\n",
    "            )\n",
    "            zy.progress.value = 6\n",
    "            show(p)\n",
    "\n",
    "        zy.progress.value = 7\n",
    "        zy.progress.value = 0\n",
    "    except Exception as ex:\n",
    "        # logger.exception(ex)\n",
    "        print('Error: {}'.format(ex))\n",
    "        print('Empty set: please change filters')\n",
    "        zy.progress.value = 0\n",
    "\n",
    "zy = widgets_utility.WidgetUtility(\n",
    "    n_topics=state.n_topics,\n",
    "    text_id='nx_id3',\n",
    "    text=wf.create_text_widget('nx_id3'),\n",
    "    scale=wf.create_float_slider('Scale', min=0.0, max=1.0, step=0.01, value=0.1),\n",
    "    year=wf.create_int_slider(\n",
    "        description='Year', min=state.min_year, max=state.max_year, step=1, value=state.min_year\n",
    "    ),\n",
    "    n_words=wf.create_int_slider(description='#words*', min=10, max=500, step=1, value=20),\n",
    "    metric=wf.create_select_widget(label='Metric*', values=list(DISTANCE_METRICS.keys()), default='Euclidean'),\n",
    "    threshold=wf.create_float_slider('Threshold', min=0.0, max=1.0, step=0.01, value=0.01),\n",
    "    output_format=wf.create_select_widget('Format', ['Network', 'List'], default='Network'),\n",
    "    layout=wf.create_select_widget('Layout', list(layout_algorithms.keys()), default='Fruchterman-Reingold'),\n",
    "    progress=wf.create_int_progress_widget(min=0, max=7, step=1, value=0, layout=widgets.Layout(width=\"90%\"))\n",
    ") \n",
    "    \n",
    "wy = widgets.interactive(\n",
    "    display_correlation_network,\n",
    "    layout_algorithm=zy.layout,\n",
    "    threshold=zy.threshold,\n",
    "    scale=zy.scale,\n",
    "    metric=zy.metric,\n",
    "    n_words=zy.n_words,\n",
    "    output_format=zy.output_format\n",
    ")\n",
    "\n",
    "display(widgets.VBox(\n",
    "    (zy.text, ) +\n",
    "    (widgets.HBox((zy.threshold,) + (zy.metric,) + (zy.output_format,)),) +\n",
    "    (widgets.HBox((zy.n_words,) + (zy.layout,) + (zy.scale,)),) +\n",
    "    (zy.progress,) +\n",
    "    (wy.children[-1],)))\n",
    "\n",
    "wy.update()\n",
    "                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "with open('sttm_corpus_text.txt', 'r') as f:\n",
    "    corpus = [ x.rstrip().split(' ') for x in f.read().split('\\n') if x != '' ]\n",
    "    \n",
    "id2word = gensim.corpora.dictionary.Dictionary(documents=corpus)\n",
    "bow_corpus = [ id2word.doc2bow(doc) for doc in corpus ]\n",
    "\n",
    "sstm_jar_path = '../../../source/STTM/STTM.jar'\n",
    "\n",
    "btm_model = WrapperSTTM(\n",
    "     sstm_jar_path,\n",
    "     model='BTM',\n",
    "     corpus=bow_corpus,\n",
    "     id2word=id2word,\n",
    "     #vectors,\n",
    "     num_topics=20,\n",
    "     #alpha=0.1,\n",
    "     #beta=0.01,\n",
    "     iterations=2000,\n",
    "     prefix='results/',\n",
    "     name='test_model'\n",
    "     #twords=20,\n",
    "     #sstep=0\n",
    ")\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pyLDAvis tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "pyLDAvis Prepare\n",
    "===============\n",
    "Main transformation functions for preparing LDAdata to the visualization's data structures\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from past.builtins import basestring\n",
    "from collections import namedtuple\n",
    "import json\n",
    "import logging\n",
    "from joblib import Parallel, delayed, cpu_count\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import entropy\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "#from .utils import NumPyEncoder\n",
    "try:\n",
    "    from sklearn.manifold import MDS, TSNE\n",
    "    sklearn_present = True\n",
    "except ImportError:\n",
    "    sklearn_present = False\n",
    "\n",
    "\n",
    "def __num_dist_rows__(array, ndigits=2):\n",
    "    return array.shape[0] - int((pd.DataFrame(array).sum(axis=1) < 0.999).sum())\n",
    "\n",
    "\n",
    "class ValidationError(ValueError):\n",
    "    pass\n",
    "\n",
    "\n",
    "def _input_check(topic_term_dists, doc_topic_dists, doc_lengths, vocab, term_frequency):\n",
    "    ttds = topic_term_dists.shape\n",
    "    dtds = doc_topic_dists.shape\n",
    "    errors = []\n",
    "    def err(msg):\n",
    "        errors.append(msg)\n",
    "\n",
    "    if dtds[1] != ttds[0]:\n",
    "        err('Number of rows of topic_term_dists does not match number of columns of doc_topic_dists; both should be equal to the number of topics in the model.')\n",
    "\n",
    "    if len(doc_lengths) != dtds[0]:\n",
    "        err('Length of doc_lengths not equal to the number of rows in doc_topic_dists; both should be equal to the number of documents in the data.')\n",
    "\n",
    "    W = len(vocab)\n",
    "    if ttds[1] != W:\n",
    "        err('Number of terms in vocabulary does not match the number of columns of topic_term_dists (where each row of topic_term_dists is a probability distribution of terms for a given topic).')\n",
    "    if len(term_frequency) != W:\n",
    "        err('Length of term_frequency not equal to the number of terms in the vocabulary (len of vocab).')\n",
    "\n",
    "    if __num_dist_rows__(topic_term_dists) != ttds[0]:\n",
    "        err('Not all rows (distributions) in topic_term_dists sum to 1.')\n",
    "\n",
    "    if __num_dist_rows__(doc_topic_dists) != dtds[0]:\n",
    "        err('Not all rows (distributions) in doc_topic_dists sum to 1.')\n",
    "\n",
    "    if len(errors) > 0:\n",
    "        return errors\n",
    "\n",
    "\n",
    "def _input_validate(*args):\n",
    "    res = _input_check(*args)\n",
    "    if res:\n",
    "        raise ValidationError('\\n' + '\\n'.join([' * ' + s for s in res]))\n",
    "\n",
    "\n",
    "def _jensen_shannon(_P, _Q):\n",
    "    _M = 0.5 * (_P + _Q)\n",
    "    return 0.5 * (entropy(_P, _M) + entropy(_Q, _M))\n",
    "\n",
    "\n",
    "def _pcoa(pair_dists, n_components=2):\n",
    "    \"\"\"Principal Coordinate Analysis,\n",
    "    aka Classical Multidimensional Scaling\n",
    "    \"\"\"\n",
    "    # code referenced from skbio.stats.ordination.pcoa\n",
    "    # https://github.com/biocore/scikit-bio/blob/0.5.0/skbio/stats/ordination/_principal_coordinate_analysis.py\n",
    "\n",
    "    # pairwise distance matrix is assumed symmetric\n",
    "    pair_dists = np.asarray(pair_dists, np.float64)\n",
    "\n",
    "    # perform SVD on double centred distance matrix\n",
    "    n = pair_dists.shape[0]\n",
    "    H = np.eye(n) - np.ones((n, n)) / n\n",
    "    B = - H.dot(pair_dists ** 2).dot(H) / 2\n",
    "    eigvals, eigvecs = np.linalg.eig(B)\n",
    "\n",
    "    # Take first n_components of eigenvalues and eigenvectors\n",
    "    # sorted in decreasing order\n",
    "    ix = eigvals.argsort()[::-1][:n_components]\n",
    "    eigvals = eigvals[ix]\n",
    "    eigvecs = eigvecs[:, ix]\n",
    "\n",
    "    # replace any remaining negative eigenvalues and associated eigenvectors with zeroes\n",
    "    # at least 1 eigenvalue must be zero\n",
    "    eigvals[np.isclose(eigvals, 0)] = 0\n",
    "    if np.any(eigvals < 0):\n",
    "        ix_neg = eigvals < 0\n",
    "        eigvals[ix_neg] = np.zeros(eigvals[ix_neg].shape)\n",
    "        eigvecs[:, ix_neg] = np.zeros(eigvecs[:, ix_neg].shape)\n",
    "\n",
    "    return np.sqrt(eigvals) * eigvecs\n",
    "\n",
    "\n",
    "def js_PCoA(distributions):\n",
    "    \"\"\"Dimension reduction via Jensen-Shannon Divergence & Principal Coordinate Analysis\n",
    "    (aka Classical Multidimensional Scaling)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    distributions : array-like, shape (`n_dists`, `k`)\n",
    "        Matrix of distributions probabilities.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pcoa : array, shape (`n_dists`, 2)\n",
    "    \"\"\"\n",
    "    dist_matrix = squareform(pdist(distributions, metric=_jensen_shannon))\n",
    "    return _pcoa(dist_matrix)\n",
    "\n",
    "\n",
    "def js_MMDS(distributions, **kwargs):\n",
    "    \"\"\"Dimension reduction via Jensen-Shannon Divergence & Metric Multidimensional Scaling\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    distributions : array-like, shape (`n_dists`, `k`)\n",
    "        Matrix of distributions probabilities.\n",
    "\n",
    "    **kwargs : Keyword argument to be passed to `sklearn.manifold.MDS()`\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mmds : array, shape (`n_dists`, 2)\n",
    "    \"\"\"\n",
    "    dist_matrix = squareform(pdist(distributions, metric=_jensen_shannon))\n",
    "    model = MDS(n_components=2, random_state=0, dissimilarity='precomputed', **kwargs)\n",
    "    return model.fit_transform(dist_matrix)\n",
    "\n",
    "\n",
    "def js_TSNE(distributions, **kwargs):\n",
    "    \"\"\"Dimension reduction via Jensen-Shannon Divergence & t-distributed Stochastic Neighbor Embedding\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    distributions : array-like, shape (`n_dists`, `k`)\n",
    "        Matrix of distributions probabilities.\n",
    "\n",
    "    **kwargs : Keyword argument to be passed to `sklearn.manifold.TSNE()`\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tsne : array, shape (`n_dists`, 2)\n",
    "    \"\"\"\n",
    "    dist_matrix = squareform(pdist(distributions, metric=_jensen_shannon))\n",
    "    model = TSNE(n_components=2, random_state=0, metric='precomputed', **kwargs)\n",
    "    return model.fit_transform(dist_matrix)\n",
    "\n",
    "\n",
    "def _df_with_names(data, index_name, columns_name):\n",
    "    if type(data) == pd.DataFrame:\n",
    "      # we want our index to be numbered\n",
    "      df = pd.DataFrame(data.values)\n",
    "    else:\n",
    "        df = pd.DataFrame(data)\n",
    "    df.index.name = index_name\n",
    "    df.columns.name = columns_name\n",
    "    return df\n",
    "\n",
    "def _series_with_name(data, name):\n",
    "    if type(data) == pd.Series:\n",
    "        data.name = name\n",
    "        # ensures a numeric index\n",
    "        return data.reset_index()[name]\n",
    "    else:\n",
    "        return pd.Series(data, name=name)\n",
    "\n",
    "def _topic_coordinates(mds, topic_term_dists, topic_proportion):\n",
    "    K = topic_term_dists.shape[0]\n",
    "    mds_res = mds(topic_term_dists)\n",
    "    assert mds_res.shape == (K, 2)\n",
    "    mds_df = pd.DataFrame({'x': mds_res[:,0], 'y': mds_res[:,1], 'topics': range(1, K + 1), \\\n",
    "                          'cluster': 1, 'Freq': topic_proportion * 100})\n",
    "    # note: cluster (should?) be deprecated soon. See: https://github.com/cpsievert/LDAvis/issues/26\n",
    "    return mds_df\n",
    "\n",
    "def _chunks(l, n):\n",
    "    \"\"\" Yield successive n-sized chunks from l.\n",
    "    \"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i+n]\n",
    "\n",
    "def _job_chunks(l, n_jobs):\n",
    "    n_chunks = n_jobs\n",
    "    if n_jobs < 0:\n",
    "        # so, have n chunks if we are using all n cores/cpus\n",
    "        n_chunks = cpu_count() + 1 - n_jobs\n",
    "    return _chunks(l, n_chunks)\n",
    "\n",
    "def _find_relevance(log_ttd, log_lift, R, lambda_):\n",
    "    relevance = lambda_ * log_ttd + (1 - lambda_) * log_lift\n",
    "    return relevance.T.apply(lambda s: s.sort_values(ascending=False).index).head(R)\n",
    "\n",
    "def _find_relevance_chunks(log_ttd, log_lift, R, lambda_seq):\n",
    "    return pd.concat([_find_relevance(log_ttd, log_lift, R, l) for l in lambda_seq])\n",
    "\n",
    "def _topic_info(topic_term_dists, topic_proportion, term_frequency, term_topic_freq, vocab, lambda_step, R, n_jobs):\n",
    "    # marginal distribution over terms (width of blue bars)\n",
    "    term_proportion = term_frequency / term_frequency.sum()\n",
    "\n",
    "    # compute the distinctiveness and saliency of the terms:\n",
    "    # this determines the R terms that are displayed when no topic is selected\n",
    "    topic_given_term = topic_term_dists / topic_term_dists.sum()\n",
    "    kernel = (topic_given_term * np.log((topic_given_term.T / topic_proportion).T))\n",
    "    distinctiveness = kernel.sum()\n",
    "    saliency = term_proportion * distinctiveness\n",
    "\n",
    "    # Order the terms for the \"default\" view by decreasing saliency:\n",
    "    default_term_info  = pd.DataFrame({'saliency': saliency, 'Term': vocab, \\\n",
    "                                      'Freq': term_frequency, 'Total': term_frequency, \\\n",
    "                                      'Category': 'Default'}). \\\n",
    "      sort_values(by='saliency', ascending=False). \\\n",
    "      head(R).drop('saliency', 1)\n",
    "    # Rounding Freq and Total to integer values to match LDAvis code:\n",
    "    default_term_info['Freq'] = np.floor(default_term_info['Freq'])\n",
    "    default_term_info['Total'] = np.floor(default_term_info['Total'])\n",
    "    ranks = np.arange(R, 0, -1)\n",
    "    default_term_info['logprob'] = default_term_info['loglift'] = ranks\n",
    "\n",
    "    ## compute relevance and top terms for each topic\n",
    "    log_lift = np.log(topic_term_dists / term_proportion)\n",
    "    log_ttd = np.log(topic_term_dists)\n",
    "    lambda_seq = np.arange(0, 1 + lambda_step, lambda_step)\n",
    "\n",
    "    def topic_top_term_df(tup):\n",
    "        new_topic_id, (original_topic_id, topic_terms) = tup\n",
    "        term_ix = topic_terms.unique()\n",
    "        return pd.DataFrame({'Term': vocab[term_ix], \\\n",
    "                           'Freq': term_topic_freq.loc[original_topic_id, term_ix], \\\n",
    "                           'Total': term_frequency[term_ix], \\\n",
    "                           'logprob': log_ttd.loc[original_topic_id, term_ix].round(4), \\\n",
    "                           'loglift': log_lift.loc[original_topic_id, term_ix].round(4), \\\n",
    "                           'Category': 'Topic%d' % new_topic_id})\n",
    "\n",
    "    top_terms = pd.concat(Parallel(n_jobs=n_jobs)(delayed(_find_relevance_chunks)(log_ttd, log_lift, R, ls) \\\n",
    "                                                 for ls in _job_chunks(lambda_seq, n_jobs)))\n",
    "    topic_dfs = map(topic_top_term_df, enumerate(top_terms.T.iterrows(), 1))\n",
    "    return pd.concat([default_term_info] + list(topic_dfs), sort=True)\n",
    "\n",
    "\n",
    "def _token_table(topic_info, term_topic_freq, vocab, term_frequency):\n",
    "    # last, to compute the areas of the circles when a term is highlighted\n",
    "    # we must gather all unique terms that could show up (for every combination\n",
    "    # of topic and value of lambda) and compute its distribution over topics.\n",
    "\n",
    "    # term-topic frequency table of unique terms across all topics and all values of lambda\n",
    "    term_ix = topic_info.index.unique()\n",
    "    term_ix = np.sort(term_ix)\n",
    "\n",
    "    top_topic_terms_freq = term_topic_freq[term_ix]\n",
    "    # use the new ordering for the topics\n",
    "    K = len(term_topic_freq)\n",
    "    top_topic_terms_freq.index = range(1, K + 1)\n",
    "    top_topic_terms_freq.index.name = 'Topic'\n",
    "\n",
    "    # we filter to Freq >= 0.5 to avoid sending too much data to the browser\n",
    "    token_table = pd.DataFrame({'Freq': top_topic_terms_freq.unstack()}). \\\n",
    "                 reset_index().set_index('term'). \\\n",
    "                 query('Freq >= 0.5')\n",
    "\n",
    "    token_table['Freq'] = token_table['Freq'].round()\n",
    "    token_table['Term'] = vocab[token_table.index.values].values\n",
    "    # Normalize token frequencies:\n",
    "    token_table['Freq'] = token_table.Freq / term_frequency[token_table.index]\n",
    "    return token_table.sort_values(by=['Term', 'Topic'])\n",
    "\n",
    "\n",
    "def vis_prepare(topic_term_dists, doc_topic_dists, doc_lengths, vocab, term_frequency, \\\n",
    "            R=30, lambda_step=0.01, mds=js_PCoA, n_jobs=-1, \\\n",
    "            plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, sort_topics=True):\n",
    "    \"\"\"Transforms the topic model distributions and related corpus data into\n",
    "    the data structures needed for the visualization.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    topic_term_dists : array-like, shape (`n_topics`, `n_terms`)\n",
    "        Matrix of topic-term probabilities. Where `n_terms` is `len(vocab)`.\n",
    "    doc_topic_dists : array-like, shape (`n_docs`, `n_topics`)\n",
    "        Matrix of document-topic probabilities.\n",
    "    doc_lengths : array-like, shape `n_docs`\n",
    "        The length of each document, i.e. the number of words in each document.\n",
    "        The order of the numbers should be consistent with the ordering of the\n",
    "        docs in `doc_topic_dists`.\n",
    "    vocab : array-like, shape `n_terms`\n",
    "        List of all the words in the corpus used to train the model.\n",
    "    term_frequency : array-like, shape `n_terms`\n",
    "        The count of each particular term over the entire corpus. The ordering\n",
    "        of these counts should correspond with `vocab` and `topic_term_dists`.\n",
    "    R : int\n",
    "        The number of terms to display in the barcharts of the visualization.\n",
    "        Default is 30. Recommended to be roughly between 10 and 50.\n",
    "    lambda_step : float, between 0 and 1\n",
    "        Determines the interstep distance in the grid of lambda values over\n",
    "        which to iterate when computing relevance.\n",
    "        Default is 0.01. Recommended to be between 0.01 and 0.1.\n",
    "    mds : function or a string representation of function\n",
    "        A function that takes `topic_term_dists` as an input and outputs a\n",
    "        `n_topics` by `2`  distance matrix. The output approximates the distance\n",
    "        between topics. See :func:`js_PCoA` for details on the default function.\n",
    "        A string representation currently accepts `pcoa` (or upper case variant),\n",
    "        `mmds` (or upper case variant) and `tsne` (or upper case variant),\n",
    "        if `sklearn` package is installed for the latter two.\n",
    "    n_jobs : int\n",
    "        The number of cores to be used to do the computations. The regular\n",
    "        joblib conventions are followed so `-1`, which is the default, will\n",
    "        use all cores.\n",
    "    plot_opts : dict, with keys 'xlab' and `ylab`\n",
    "        Dictionary of plotting options, right now only used for the axis labels.\n",
    "    sort_topics : sort topics by topic proportion (percentage of tokens covered). Set to false to\n",
    "        to keep original topic order.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    prepared_data : PreparedData\n",
    "        A named tuple containing all the data structures required to create\n",
    "        the visualization. To be passed on to functions like :func:`display`.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    This implements the method of `Sievert, C. and Shirley, K. (2014):\n",
    "    LDAvis: A Method for Visualizing and Interpreting Topics, ACL Workshop on\n",
    "    Interactive Language Learning, Visualization, and Interfaces.`\n",
    "\n",
    "    http://nlp.stanford.edu/events/illvi2014/papers/sievert-illvi2014.pdf\n",
    "\n",
    "    See Also\n",
    "    --------\n",
    "    :func:`save_json`: save json representation of a figure to file\n",
    "    :func:`save_html` : save html representation of a figure to file\n",
    "    :func:`show` : launch a local server and show a figure in a browser\n",
    "    :func:`display` : embed figure within the IPython notebook\n",
    "    :func:`enable_notebook` : automatically embed visualizations in IPython notebook\n",
    "    \"\"\"\n",
    "    # parse mds\n",
    "    if isinstance(mds, basestring):\n",
    "        mds = mds.lower()\n",
    "        if mds == 'pcoa':\n",
    "            mds = js_PCoA\n",
    "        elif mds in ('mmds', 'tsne'):\n",
    "            if sklearn_present:\n",
    "                mds_opts = {'mmds': js_MMDS, 'tsne': js_TSNE}\n",
    "                mds = mds_opts[mds]\n",
    "            else:\n",
    "                logging.warning('sklearn not present, switch to PCoA')\n",
    "                mds = js_PCoA\n",
    "        else:\n",
    "            logging.warning('Unknown mds `%s`, switch to PCoA' % mds)\n",
    "            mds = js_PCoA\n",
    "\n",
    "    topic_term_dists = _df_with_names(topic_term_dists, 'topic', 'term')\n",
    "    doc_topic_dists  = _df_with_names(doc_topic_dists, 'doc', 'topic')\n",
    "    term_frequency   = _series_with_name(term_frequency, 'term_frequency')\n",
    "    doc_lengths      = _series_with_name(doc_lengths, 'doc_length')\n",
    "    vocab            = _series_with_name(vocab, 'vocab')\n",
    "    _input_validate(topic_term_dists, doc_topic_dists, doc_lengths, vocab, term_frequency)\n",
    "    R = min(R, len(vocab))\n",
    "\n",
    "    topic_freq       = (doc_topic_dists.T * doc_lengths).T.sum()\n",
    "    # topic_freq       = np.dot(doc_topic_dists.T, doc_lengths)\n",
    "    if (sort_topics):\n",
    "        topic_proportion = (topic_freq / topic_freq.sum()).sort_values(ascending=False)\n",
    "    else:\n",
    "        topic_proportion = (topic_freq / topic_freq.sum())\n",
    "\n",
    "    topic_order      = topic_proportion.index\n",
    "    # reorder all data based on new ordering of topics\n",
    "    topic_freq       = topic_freq[topic_order]\n",
    "    topic_term_dists = topic_term_dists.iloc[topic_order]\n",
    "    doc_topic_dists  = doc_topic_dists[topic_order]\n",
    "\n",
    "    # token counts for each term-topic combination (widths of red bars)\n",
    "    term_topic_freq = (topic_term_dists.T * topic_freq).T\n",
    "    ## Quick fix for red bar width bug.  We calculate the\n",
    "    ## term frequencies internally, using the topic term distributions and the\n",
    "    ## topic frequencies, rather than using the user-supplied term frequencies.\n",
    "    ## For a detailed discussion, see: https://github.com/cpsievert/LDAvis/pull/41\n",
    "    term_frequency = np.sum(term_topic_freq, axis=0)\n",
    "\n",
    "    topic_info         = _topic_info(topic_term_dists, topic_proportion, term_frequency, term_topic_freq, vocab, lambda_step, R, n_jobs)\n",
    "    token_table        = _token_table(topic_info, term_topic_freq, vocab, term_frequency)\n",
    "    topic_coordinates = _topic_coordinates(mds, topic_term_dists, topic_proportion)\n",
    "    client_topic_order = [x + 1 for x in topic_order]\n",
    "\n",
    "    return PreparedData(topic_coordinates, topic_info, token_table, R, lambda_step, plot_opts, client_topic_order)\n",
    "\n",
    "class PreparedData(namedtuple('PreparedData', ['topic_coordinates', 'topic_info', 'token_table',\\\n",
    "                                               'R', 'lambda_step', 'plot_opts', 'topic_order'])):\n",
    "    def to_dict(self):\n",
    "        return {'mdsDat': self.topic_coordinates.to_dict(orient='list'),\n",
    "               'tinfo': self.topic_info.to_dict(orient='list'),\n",
    "               'token.table': self.token_table.to_dict(orient='list'),\n",
    "               'R': self.R,\n",
    "               'lambda.step': self.lambda_step,\n",
    "               'plot.opts': self.plot_opts,\n",
    "               'topic.order': self.topic_order}\n",
    "\n",
    "    #def to_json(self):\n",
    "    #    return json.dumps(self.to_dict(), cls=NumPyEncoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "pyLDAvis Gensim\n",
    "===============\n",
    "Helper functions to visualize LDA models trained by Gensim\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "import funcy as fp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import issparse\n",
    "from past.builtins import xrange\n",
    "#from . import prepare as vis_prepare\n",
    "\n",
    "def _extract_data(topic_model, corpus, dictionary, doc_topic_dists=None):\n",
    "   import gensim\n",
    "\n",
    "   if not gensim.matutils.ismatrix(corpus):\n",
    "      corpus_csc = gensim.matutils.corpus2csc(corpus, num_terms=len(dictionary))\n",
    "   else:\n",
    "      corpus_csc = corpus\n",
    "      # Need corpus to be a streaming gensim list corpus for len and inference functions below:\n",
    "      corpus = gensim.matutils.Sparse2Corpus(corpus_csc)\n",
    "\n",
    "   vocab = list(dictionary.token2id.keys())\n",
    "   # TODO: add the hyperparam to smooth it out? no beta in online LDA impl.. hmm..\n",
    "   # for now, I'll just make sure we don't ever get zeros...\n",
    "   beta = 0.01\n",
    "   fnames_argsort = np.asarray(list(dictionary.token2id.values()), dtype=np.int_)\n",
    "   term_freqs = corpus_csc.sum(axis=1).A.ravel()[fnames_argsort]\n",
    "   term_freqs[term_freqs == 0] = beta\n",
    "   doc_lengths = corpus_csc.sum(axis=0).A.ravel()\n",
    "\n",
    "   assert term_freqs.shape[0] == len(dictionary), 'Term frequencies and dictionary have different shape {} != {}'.format(term_freqs.shape[0], len(dictionary))\n",
    "   assert doc_lengths.shape[0] == len(corpus), 'Document lengths and corpus have different sizes {} != {}'.format(doc_lengths.shape[0], len(corpus))\n",
    "\n",
    "   if hasattr(topic_model, 'lda_alpha'):\n",
    "       num_topics = len(topic_model.lda_alpha)\n",
    "   else:\n",
    "       num_topics = topic_model.num_topics\n",
    "\n",
    "   if doc_topic_dists is None:\n",
    "      # If its an HDP model.\n",
    "      if hasattr(topic_model, 'lda_beta'):\n",
    "          gamma = topic_model.inference(corpus)\n",
    "      else:\n",
    "          gamma, _ = topic_model.inference(corpus)\n",
    "      doc_topic_dists = gamma / gamma.sum(axis=1)[:, None]\n",
    "   else:\n",
    "      if isinstance(doc_topic_dists, list):\n",
    "         doc_topic_dists = gensim.matutils.corpus2dense(doc_topic_dists, num_topics).T\n",
    "      elif issparse(doc_topic_dists):\n",
    "         doc_topic_dists = doc_topic_dists.T.todense()\n",
    "      doc_topic_dists = doc_topic_dists / doc_topic_dists.sum(axis=1)\n",
    "\n",
    "   assert doc_topic_dists.shape[1] == num_topics, 'Document topics and number of topics do not match {} != {}'.format(doc_topic_dists.shape[1], num_topics)\n",
    "\n",
    "   # get the topic-term distribution straight from gensim without\n",
    "   # iterating over tuples\n",
    "   if hasattr(topic_model, 'lda_beta'):\n",
    "       topic = topic_model.lda_beta\n",
    "   else:\n",
    "       topic = topic_model.state.get_lambda()\n",
    "   topic = topic / topic.sum(axis=1)[:, None]\n",
    "   topic_term_dists = topic[:, fnames_argsort]\n",
    "\n",
    "   assert topic_term_dists.shape[0] == doc_topic_dists.shape[1]\n",
    "\n",
    "   return {'topic_term_dists': topic_term_dists, 'doc_topic_dists': doc_topic_dists,\n",
    "           'doc_lengths': doc_lengths, 'vocab': vocab, 'term_frequency': term_freqs}\n",
    "\n",
    "def prepare(topic_model, corpus, dictionary, doc_topic_dist=None, **kwargs):\n",
    "    \"\"\"Transforms the Gensim TopicModel and related corpus and dictionary into\n",
    "    the data structures needed for the visualization.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    topic_model : gensim.models.ldamodel.LdaModel\n",
    "        An already trained Gensim LdaModel. The other gensim model types are\n",
    "        not supported (PRs welcome).\n",
    "\n",
    "    corpus : array-like list of bag of word docs in tuple form or scipy CSC matrix\n",
    "        The corpus in bag of word form, the same docs used to train the model.\n",
    "        The corpus is transformed into a csc matrix internally, if you intend to\n",
    "        call prepare multiple times it is a good idea to first call\n",
    "        `gensim.matutils.corpus2csc(corpus)` and pass in the csc matrix instead.\n",
    "\n",
    "    For example: [(50, 3), (63, 5), ....]\n",
    "\n",
    "    dictionary: gensim.corpora.Dictionary\n",
    "        The dictionary object used to create the corpus. Needed to extract the\n",
    "        actual terms (not ids).\n",
    "\n",
    "    doc_topic_dist (optional): Document topic distribution from LDA (default=None)\n",
    "        The document topic distribution that is eventually visualised, if you will\n",
    "        be calling `prepare` multiple times it's a good idea to explicitly pass in\n",
    "        `doc_topic_dist` as inferring this for large corpora can be quite\n",
    "        expensive.\n",
    "\n",
    "    **kwargs :\n",
    "        additional keyword arguments are passed through to :func:`pyldavis.prepare`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    prepared_data : PreparedData\n",
    "        the data structures used in the visualization\n",
    "\n",
    "    Example\n",
    "    --------\n",
    "    For example usage please see this notebook:\n",
    "    http://nbviewer.ipython.org/github/bmabey/pyLDAvis/blob/master/notebooks/Gensim%20Newsgroup.ipynb\n",
    "\n",
    "    See\n",
    "    ------\n",
    "    See `pyLDAvis.prepare` for **kwargs.\n",
    "    \"\"\"\n",
    "    opts = fp.merge(_extract_data(topic_model, corpus, dictionary, doc_topic_dist), kwargs)\n",
    "    return vis_prepare(**opts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 655.4,
   "position": {
    "height": "886px",
    "left": "1049px",
    "right": "20px",
    "top": "110px",
    "width": "654px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
