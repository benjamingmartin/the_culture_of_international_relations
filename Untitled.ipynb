{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_discriminating_terms(\n",
    "    terms_lists, bool_array_grp1, *, max_n_terms=1000, top_n_terms=25\n",
    "):\n",
    "    \"\"\"\n",
    "    Given a collection of documents assigned to one of 2 exclusive groups, get the\n",
    "    ``top_n_terms`` most discriminating terms for group1-and-not-group2 and\n",
    "    group2-and-not-group1.\n",
    "\n",
    "    Args:\n",
    "        terms_lists (Iterable[Iterable[str]]): Sequence of documents, each as a\n",
    "            sequence of (str) terms; used as input to :func:`doc_term_matrix()`\n",
    "        bool_array_grp1 (Iterable[bool]): Ordered sequence of True/False values,\n",
    "            where True corresponds to documents falling into \"group 1\" and False\n",
    "            corresponds to those in \"group 2\".\n",
    "        max_n_terms (int): Only consider terms whose document frequency is within\n",
    "            the top ``max_n_terms`` out of all distinct terms; must be > 0.\n",
    "        top_n_terms (int or float): If int (must be > 0), the total number of most\n",
    "            discriminating terms to return for each group; if float (must be in\n",
    "            the interval (0, 1)), the fraction of ``max_n_terms`` to return for each group.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: Top ``top_n_terms`` most discriminating terms for grp1-not-grp2\n",
    "        List[str]: Top ``top_n_terms`` most discriminating terms for grp2-not-grp1\n",
    "\n",
    "    References:\n",
    "        King, Gary, Patrick Lam, and Margaret Roberts. \"Computer-Assisted Keyword\n",
    "        and Document Set Discovery from Unstructured Text.\" (2014).\n",
    "        http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.458.1445&rep=rep1&type=pdf\n",
    "    \"\"\"\n",
    "    \n",
    "    = 1\n",
    "    alpha_grp2 = 1\n",
    "    if isinstance(top_n_terms, float):\n",
    "        top_n_terms = top_n_terms * max_n_terms\n",
    "    bool_array_grp1 = np.array(bool_array_grp1)\n",
    "    bool_array_grp2 = np.invert(bool_array_grp1)\n",
    "\n",
    "    vectorizer = vsm.Vectorizer(\n",
    "        tf_type=\"linear\",\n",
    "        norm=None,\n",
    "        idf_type=\"smooth\",\n",
    "        min_df=3,\n",
    "        max_df=0.95,\n",
    "        max_n_terms=max_n_terms,\n",
    "    )\n",
    "    dtm = vectorizer.fit_transform(terms_lists)\n",
    "    id2term = vectorizer.id_to_term\n",
    "\n",
    "    # get doc freqs for all terms in grp1 documents\n",
    "    dtm_grp1 = dtm[bool_array_grp1, :]\n",
    "    n_docs_grp1 = dtm_grp1.shape[0]\n",
    "    doc_freqs_grp1 = vsm.get_doc_freqs(dtm_grp1)\n",
    "\n",
    "    # get doc freqs for all terms in grp2 documents\n",
    "    dtm_grp2 = dtm[bool_array_grp2, :]\n",
    "    n_docs_grp2 = dtm_grp2.shape[0]\n",
    "    doc_freqs_grp2 = vsm.get_doc_freqs(dtm_grp2)\n",
    "\n",
    "    # get terms that occur in a larger fraction of grp1 docs than grp2 docs\n",
    "    term_ids_grp1 = np.where(\n",
    "        doc_freqs_grp1 / n_docs_grp1 > doc_freqs_grp2 / n_docs_grp2\n",
    "    )[0]\n",
    "\n",
    "    # get terms that occur in a larger fraction of grp2 docs than grp1 docs\n",
    "    term_ids_grp2 = np.where(\n",
    "        doc_freqs_grp1 / n_docs_grp1 < doc_freqs_grp2 / n_docs_grp2\n",
    "    )[0]\n",
    "\n",
    "    # get grp1 terms doc freqs in and not-in grp1 and grp2 docs, plus marginal totals\n",
    "    grp1_terms_grp1_df = doc_freqs_grp1[term_ids_grp1]\n",
    "    grp1_terms_grp2_df = doc_freqs_grp2[term_ids_grp1]\n",
    "    # grp1_terms_grp1_not_df = n_docs_grp1 - grp1_terms_grp1_df\n",
    "    # grp1_terms_grp2_not_df = n_docs_grp2 - grp1_terms_grp2_df\n",
    "    # grp1_terms_total_df = grp1_terms_grp1_df + grp1_terms_grp2_df\n",
    "    # grp1_terms_total_not_df = grp1_terms_grp1_not_df + grp1_terms_grp2_not_df\n",
    "\n",
    "    # get grp2 terms doc freqs in and not-in grp2 and grp1 docs, plus marginal totals\n",
    "    grp2_terms_grp2_df = doc_freqs_grp2[term_ids_grp2]\n",
    "    grp2_terms_grp1_df = doc_freqs_grp1[term_ids_grp2]\n",
    "    # grp2_terms_grp2_not_df = n_docs_grp2 - grp2_terms_grp2_df\n",
    "    # grp2_terms_grp1_not_df = n_docs_grp1 - grp2_terms_grp1_df\n",
    "    # grp2_terms_total_df = grp2_terms_grp2_df + grp2_terms_grp1_df\n",
    "    # grp2_terms_total_not_df = grp2_terms_grp2_not_df + grp2_terms_grp1_not_df\n",
    "    \n",
    "    def loglikelihood(x, y)\n",
    "            return (x - 1)! * (y - 1)! / (x + y - 1)!\n",
    "            \n",
    "    # get grp1 terms likelihoods, then sort for most discriminating grp1-not-grp2 terms\n",
    "    grp1_terms_likelihoods = {}\n",
    "    for idx, term_id in enumerate(term_ids_grp1):\n",
    "        term1 = (\n",
    "            Decimal(math.factorial(grp1_terms_grp1_df[idx] + alpha_grp1 - 1))\n",
    "            * Decimal(math.factorial(grp1_terms_grp2_df[idx] + alpha_grp2 - 1))\n",
    "            / Decimal(\n",
    "                math.factorial(\n",
    "                    grp1_terms_grp1_df[idx]\n",
    "                    + grp1_terms_grp2_df[idx]\n",
    "                    + alpha_grp1\n",
    "                    + alpha_grp2\n",
    "                    - 1\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        term2 = (\n",
    "            Decimal(\n",
    "                math.factorial(n_docs_grp1 - grp1_terms_grp1_df[idx] + alpha_grp1 - 1)\n",
    "            )\n",
    "            * Decimal(\n",
    "                math.factorial(n_docs_grp2 - grp1_terms_grp2_df[idx] + alpha_grp2 - 1)\n",
    "            )\n",
    "            / Decimal(\n",
    "                (\n",
    "                    math.factorial(\n",
    "                        n_docs_grp1\n",
    "                        + n_docs_grp2\n",
    "                        - grp1_terms_grp1_df[idx]\n",
    "                        - grp1_terms_grp2_df[idx]\n",
    "                        + alpha_grp1\n",
    "                        + alpha_grp2\n",
    "                        - 1\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        grp1_terms_likelihoods[id2term[term_id]] = term1 * term2\n",
    "    top_grp1_terms = [\n",
    "        term\n",
    "        for term, likelihood in sorted(\n",
    "            grp1_terms_likelihoods.items(), key=operator.itemgetter(1), reverse=True\n",
    "        )[:top_n_terms]\n",
    "    ]\n",
    "\n",
    "    # get grp2 terms likelihoods, then sort for most discriminating grp2-not-grp1 terms\n",
    "    grp2_terms_likelihoods = {}\n",
    "    for idx, term_id in enumerate(term_ids_grp2):\n",
    "        term1 = (\n",
    "            Decimal(math.factorial(grp2_terms_grp2_df[idx] + alpha_grp2 - 1))\n",
    "            * Decimal(math.factorial(grp2_terms_grp1_df[idx] + alpha_grp1 - 1))\n",
    "            / Decimal(\n",
    "                math.factorial(\n",
    "                    grp2_terms_grp2_df[idx]\n",
    "                    + grp2_terms_grp1_df[idx]\n",
    "                    + alpha_grp2\n",
    "                    + alpha_grp1\n",
    "                    - 1\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        term2 = (\n",
    "            Decimal(math.factorial(n_docs_grp2 - grp2_terms_grp2_df[idx] + alpha_grp2 - 1))\n",
    "            * Decimal(math.factorial(n_docs_grp1 - grp2_terms_grp1_df[idx] + alpha_grp1 - 1))\n",
    "            / Decimal(\n",
    "                (\n",
    "                    math.factorial(\n",
    "                        n_docs_grp2\n",
    "                        + n_docs_grp1\n",
    "                        - grp2_terms_grp2_df[idx]\n",
    "                        - grp2_terms_grp1_df[idx]\n",
    "                        + alpha_grp2\n",
    "                        + alpha_grp1\n",
    "                        - 1\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        grp2_terms_likelihoods[id2term[term_id]] = term1 * term2\n",
    "    top_grp2_terms = [\n",
    "        term\n",
    "        for term, likelihood in sorted(\n",
    "            grp2_terms_likelihoods.items(), key=operator.itemgetter(1), reverse=True\n",
    "        )[:top_n_terms]\n",
    "    ]\n",
    "\n",
    "    return (top_grp1_terms, top_grp2_terms)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
